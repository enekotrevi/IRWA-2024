{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f29239-b610-4297-a58e-b64b68342580",
   "metadata": {
    "id": "c2f29239-b610-4297-a58e-b64b68342580"
   },
   "source": [
    "## IRWA Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c48446-68e3-4a1d-9b09-4b9c7507e864",
   "metadata": {
    "id": "95c48446-68e3-4a1d-9b09-4b9c7507e864"
   },
   "source": [
    "#### Load Python packages\n",
    "Let's first import all the packages that we will need during the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04627a52-701d-4a26-9b6a-198598094921",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10216,
     "status": "ok",
     "timestamp": 1731080919532,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "04627a52-701d-4a26-9b6a-198598094921",
    "outputId": "a064b957-b035-4d3f-c8ee-c3cbe1afde8f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bertamitjavilapita/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bertamitjavilapita/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d42f597-1dc8-4884-8094-07b3da6ca248",
   "metadata": {
    "executionInfo": {
     "elapsed": 2595,
     "status": "ok",
     "timestamp": 1731080922123,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "9d42f597-1dc8-4884-8094-07b3da6ca248"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "import time\n",
    "import re\n",
    "from collections import Counter\n",
    "import statistics\n",
    "import json\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import ast\n",
    "import pickle\n",
    "# import rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f89a0-85db-463a-b92a-76c49b559be6",
   "metadata": {
    "id": "1a7f89a0-85db-463a-b92a-76c49b559be6"
   },
   "source": [
    "#### Load data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dujpjqneb5Zv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23048,
     "status": "ok",
     "timestamp": 1731080945163,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "dujpjqneb5Zv",
    "outputId": "8a202533-b604-4f9b-dc9f-ae074d53d237"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc6f0b1-38b0-49ab-92f4-6bfdbaca49f4",
   "metadata": {
    "id": "bbc6f0b1-38b0-49ab-92f4-6bfdbaca49f4"
   },
   "source": [
    "**Data:** we import the pickle, i.e. the serialized data from create_index_tfidf from part 2. We need need term frequencies, document frequencies, the idf values and index for each term in the collection. And dataset of processed tweets that contains the following information for each tweet: Tweet, Date, Hashtags, Hashtags_count, Likes, Retweets, Url, and docId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f55439d0-1614-4c8f-b127-741f33ef448b",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1731080945163,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "f55439d0-1614-4c8f-b127-741f33ef448b"
   },
   "outputs": [],
   "source": [
    "doc_path = '/content/drive/MyDrive/PROJECT IRWA/Part 2/Data/'\n",
    "doc_path = '/Users/bertamitjavilapita/Desktop/BERTA/UPF/4RT/IRWA/PROJECT/Part 2/Data/'\n",
    "# lo load the serialized data for future use\n",
    "def load_serialized_data(filepath=\"index_data.pkl\"):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        index, tf, df, idf = pickle.load(f)\n",
    "    return index, tf, df, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db28861-5dc4-4ca9-ae53-52b58986192d",
   "metadata": {
    "executionInfo": {
     "elapsed": 7614,
     "status": "ok",
     "timestamp": 1731080952773,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "3db28861-5dc4-4ca9-ae53-52b58986192d"
   },
   "outputs": [],
   "source": [
    "# load the serialized data from the file for future use\n",
    "index, tf, df, idf = load_serialized_data(filepath=doc_path + \"index_data.pkl\")\n",
    "processed_tweets_df = pd.read_csv(doc_path + 'processed_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1467cc95-a293-4a86-9a4c-bc422ffeed50",
   "metadata": {
    "id": "1467cc95-a293-4a86-9a4c-bc422ffeed50"
   },
   "source": [
    "### Part 3: Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e014c35-7b3b-4cb4-94dc-7999be8bb72b",
   "metadata": {
    "id": "0e014c35-7b3b-4cb4-94dc-7999be8bb72b"
   },
   "source": [
    "**Ranking score: Given a query, we want to get the top-20 documents related to the query.**\n",
    "\n",
    "Queries definition:\n",
    "- \"Indian government response to farmers\"\n",
    "- \"International support for farmers\"\n",
    "- \"Demands of farmers' protests\"\n",
    "- \"Police action during farmers protest\"\n",
    "- \"Schedules and locations of demonstrations and protests\"\n",
    "\n",
    "**GOAL: Find all the documents that contain all the words in the query and sort them by their relevance with regard to the query.**\n",
    "\n",
    "**SCORE:**\n",
    "\n",
    "**1. You’re asked to provide 2 different ways of ranking:**\n",
    "- **TF-IDF + cosine similarity: Classical scoring, we have also seen during the practical labs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bf0051e-8fd2-46c0-b1e7-42909c9d0c27",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1731080952775,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "4bf0051e-8fd2-46c0-b1e7-42909c9d0c27"
   },
   "outputs": [],
   "source": [
    "# definition of our queries\n",
    "queries = ['Indian government response to farmers',\n",
    "           'International support for farmers',\n",
    "           \"Demands of farmers' protests\",\n",
    "           'Police action during farmers protest',\n",
    "           'Schedules and locations of demonstrations and protests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "273aa24f-3f6d-4e49-b74c-d53857b001fb",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1731080952775,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "273aa24f-3f6d-4e49-b74c-d53857b001fb"
   },
   "outputs": [],
   "source": [
    "# rank documents - tf-idf ja implementat en la part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d57f8674-5a5e-40ee-b24a-570df9ee3327",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1731080952776,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "d57f8674-5a5e-40ee-b24a-570df9ee3327"
   },
   "outputs": [],
   "source": [
    "# function from part 1 to process tweets\n",
    "def process_tweet(tweet):\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess the tweet removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "\n",
    "    Argument:\n",
    "    line -- string (tweet) to be preprocessed\n",
    "\n",
    "    Returns:\n",
    "    tweet - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer() # define the stemmer\n",
    "    stop_words = set(stopwords.words(\"english\")) # define the stopwords\n",
    "    tweet =  tweet.lower() # transform the line to lowercase\n",
    "    tweet = tweet.replace('\\\\n', '') # remove newline characters\n",
    "    tweet = ' '.join(tweet.split()) # remove extra whitespaces\n",
    "    tweet = re.sub(r'\\S*https?:\\S*', '', tweet) # delete URLs on the tweet because we won't be able to access to them\n",
    "    tweet.strip() # remove spaces at first and at the end of a message\n",
    "    tweet = re.sub(r' ?#\\S+', '', tweet) # remove word that is with the hastag - hastag is saved separately\n",
    "    tweet = re.sub(r'[^a-z0-9#@ ]+', '', tweet) # remove punctuation\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet) # delete punctuation\n",
    "    tweet = tweet.split() # tokenize the text to get a list of terms\n",
    "    tweet = [word for word in tweet if word not in stop_words] # eliminate the stopwords\n",
    "    tweet = [stemmer.stem(word) for word in tweet] # perform stemming\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f24326a1-f69c-4b69-a875-2ba1ecc229aa",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1731080952776,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "f24326a1-f69c-4b69-a875-2ba1ecc229aa"
   },
   "outputs": [],
   "source": [
    "def rank_documents(terms, docs, index, idf, tf):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "\n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "\n",
    "    Returns:\n",
    "    Print the list of ranked documents\n",
    "    \"\"\"\n",
    "\n",
    "    # I'm interested only on the element of the docVector corresponding to the query terms\n",
    "    # The remaining elements would became 0 when multiplied to the query_vector\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) # I call doc_vectors[k] for a nonexistent key k, the key-value pair (k,[0]*len(terms)) will be automatically added to the dictionary\n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms)  # get the frequency of each term in the query.\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        ## Compute tf*idf(normalize TF as done with documents)\n",
    "        query_vector[termIndex]= query_terms_count[term]/ query_norm * idf[term]\n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc_index, (doc, postings) in enumerate(index[term]):\n",
    "\n",
    "            #tf[term][0] will contain the tf of the term \"term\" in the doc 26\n",
    "            if doc in docs:\n",
    "                doc_vectors[doc][termIndex] = tf[term][doc_index] * idf[term]  # TODO: check if multiply for idf\n",
    "\n",
    "    # Calculate the score of each doc\n",
    "    # compute the cosine similarity between queyVector and each docVector:\n",
    "    # HINT: you can use the dot product because in case of normalized vectors it corresponds to the cosine similarity\n",
    "    # see np.dot\n",
    "\n",
    "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "\n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "    result_scores = [x[0] for x in doc_scores]\n",
    "\n",
    "    if len(result_docs) == 0:\n",
    "        print('No results found, try again')\n",
    "        query = input()\n",
    "        docs = search_tf_idf(query, index)\n",
    "    return result_docs, result_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c1ac0a5-dc0a-4b09-b3fd-30eab1fd2d64",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1731080952777,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "2c1ac0a5-dc0a-4b09-b3fd-30eab1fd2d64"
   },
   "outputs": [],
   "source": [
    "def search_tf_idf(query, index):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms.\n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = process_tweet(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"\n",
    "            term_docs=[posting[0] for posting in index[term]]\n",
    "            docs |= set(term_docs)\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs = rank_documents(query, docs, index, idf, tf)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de3b3341-8570-452b-bec9-550cc93387d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36264,
     "status": "ok",
     "timestamp": 1731080989030,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "de3b3341-8570-452b-bec9-550cc93387d1",
    "outputId": "1094ab82-7d39-4522-8d79-54213128eb6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 15989 retrieved documents for the query 'Indian government response to farmers':\n",
      "\n",
      "docId = doc_3234\t score = 11.8045\n",
      "docId = doc_27784\t score = 9.5898\n",
      "docId = doc_38114\t score = 9.5064\n",
      "docId = doc_38045\t score = 7.8308\n",
      "docId = doc_33082\t score = 7.8308\n",
      "docId = doc_41021\t score = 7.6648\n",
      "docId = doc_13543\t score = 7.5804\n",
      "docId = doc_7288\t score = 7.2119\n",
      "docId = doc_1353\t score = 7.0977\n",
      "docId = doc_39288\t score = 6.7811\n",
      "docId = doc_32344\t score = 6.7811\n",
      "docId = doc_24570\t score = 6.7811\n",
      "docId = doc_24061\t score = 6.7811\n",
      "docId = doc_17249\t score = 6.7811\n",
      "docId = doc_34963\t score = 6.6396\n",
      "docId = doc_37157\t score = 6.5963\n",
      "docId = doc_47642\t score = 6.3002\n",
      "docId = doc_2453\t score = 6.065\n",
      "docId = doc_19626\t score = 6.065\n",
      "docId = doc_16612\t score = 6.065\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 15767 retrieved documents for the query 'International support for farmers':\n",
      "\n",
      "docId = doc_859\t score = 10.9298\n",
      "docId = doc_21846\t score = 10.9298\n",
      "docId = doc_12950\t score = 9.6171\n",
      "docId = doc_38762\t score = 8.9963\n",
      "docId = doc_27400\t score = 8.9963\n",
      "docId = doc_21630\t score = 8.9963\n",
      "docId = doc_6713\t score = 8.0471\n",
      "docId = doc_28710\t score = 7.4676\n",
      "docId = doc_42972\t score = 7.3461\n",
      "docId = doc_31474\t score = 7.3461\n",
      "docId = doc_28358\t score = 7.3461\n",
      "docId = doc_27294\t score = 7.3461\n",
      "docId = doc_25064\t score = 7.3461\n",
      "docId = doc_17785\t score = 7.3461\n",
      "docId = doc_44066\t score = 6.9125\n",
      "docId = doc_25041\t score = 6.7455\n",
      "docId = doc_42502\t score = 6.57\n",
      "docId = doc_6920\t score = 6.3614\n",
      "docId = doc_6031\t score = 6.3614\n",
      "docId = doc_48125\t score = 6.3614\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 14911 retrieved documents for the query 'Demands of farmers' protests':\n",
      "\n",
      "docId = doc_15908\t score = 12.1176\n",
      "docId = doc_43415\t score = 8.5684\n",
      "docId = doc_11006\t score = 7.7504\n",
      "docId = doc_17929\t score = 7.5711\n",
      "docId = doc_41953\t score = 6.9967\n",
      "docId = doc_39659\t score = 6.9967\n",
      "docId = doc_1940\t score = 6.9967\n",
      "docId = doc_15930\t score = 6.9967\n",
      "docId = doc_10445\t score = 6.9967\n",
      "docId = doc_18128\t score = 6.937\n",
      "docId = doc_887\t score = 6.5562\n",
      "docId = doc_43810\t score = 6.5562\n",
      "docId = doc_43799\t score = 6.5562\n",
      "docId = doc_43790\t score = 6.5562\n",
      "docId = doc_18273\t score = 6.5562\n",
      "docId = doc_17894\t score = 6.5562\n",
      "docId = doc_28839\t score = 6.3952\n",
      "docId = doc_30921\t score = 6.3225\n",
      "docId = doc_43437\t score = 6.0588\n",
      "docId = doc_12672\t score = 6.0588\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 15935 retrieved documents for the query 'Police action during farmers protest':\n",
      "\n",
      "docId = doc_24374\t score = 11.4668\n",
      "docId = doc_13980\t score = 11.4668\n",
      "docId = doc_32026\t score = 10.1775\n",
      "docId = doc_5491\t score = 7.0523\n",
      "docId = doc_34650\t score = 6.8573\n",
      "docId = doc_14464\t score = 6.8367\n",
      "docId = doc_17561\t score = 6.8188\n",
      "docId = doc_33549\t score = 6.6209\n",
      "docId = doc_33540\t score = 6.6209\n",
      "docId = doc_32143\t score = 6.6209\n",
      "docId = doc_31632\t score = 6.6209\n",
      "docId = doc_18542\t score = 6.6209\n",
      "docId = doc_32162\t score = 6.2327\n",
      "docId = doc_41805\t score = 6.2242\n",
      "docId = doc_11674\t score = 5.9814\n",
      "docId = doc_18802\t score = 5.9385\n",
      "docId = doc_8324\t score = 5.8725\n",
      "docId = doc_41801\t score = 5.7637\n",
      "docId = doc_33548\t score = 5.7334\n",
      "docId = doc_33539\t score = 5.7334\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 4394 retrieved documents for the query 'Schedules and locations of demonstrations and protests':\n",
      "\n",
      "docId = doc_43892\t score = 22.7138\n",
      "docId = doc_46453\t score = 16.0613\n",
      "docId = doc_45516\t score = 16.0613\n",
      "docId = doc_44233\t score = 13.193\n",
      "docId = doc_45111\t score = 11.9591\n",
      "docId = doc_45564\t score = 11.496\n",
      "docId = doc_9157\t score = 10.419\n",
      "docId = doc_19010\t score = 10.419\n",
      "docId = doc_2192\t score = 9.7347\n",
      "docId = doc_17302\t score = 9.7347\n",
      "docId = doc_16783\t score = 9.7347\n",
      "docId = doc_3228\t score = 9.6849\n",
      "docId = doc_26556\t score = 9.6849\n",
      "docId = doc_41207\t score = 9.5388\n",
      "docId = doc_19312\t score = 9.5388\n",
      "docId = doc_43347\t score = 9.1338\n",
      "docId = doc_42936\t score = 8.7763\n",
      "docId = doc_38629\t score = 8.7295\n",
      "docId = doc_38189\t score = 8.7295\n",
      "docId = doc_20809\t score = 8.2594\n"
     ]
    }
   ],
   "source": [
    "top = 20\n",
    "results = {}  # dictionary to store results for each query\n",
    "\n",
    "# iterate through queries\n",
    "for i, query in enumerate(queries):\n",
    "    # execute the search function\n",
    "    ranked_docs, result_scores = search_tf_idf(query, index)\n",
    "\n",
    "    # store results in the dictionary\n",
    "    results[f'ranked_docs_q{i+1}'] = ranked_docs\n",
    "    results[f'result_scores_q{i+1}'] = result_scores\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------------------------------')\n",
    "    # print the top documents and their scores\n",
    "\n",
    "    print(f\"\\nTop {top} results out of {len(ranked_docs)} retrieved documents for the query '{query}':\\n\")\n",
    "    for doc_id, score in zip(ranked_docs[:top], result_scores[:top]):\n",
    "        print(f'docId = {doc_id}\\t score = {round(score, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b5f75f-5d88-4104-bf68-fd488735f9d0",
   "metadata": {
    "id": "62b5f75f-5d88-4104-bf68-fd488735f9d0"
   },
   "source": [
    "- **Your-Score + cosine similarity: Here the task is to create a new score, and it’s up to you to create a new one.**\n",
    "ELIMINARLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8d18b27-488e-4ca2-85f9-984f6339248b",
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1731080989031,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "f8d18b27-488e-4ca2-85f9-984f6339248b"
   },
   "outputs": [],
   "source": [
    "# Using - likes, retweets, hashtags -> change the score\n",
    "\n",
    "# hem de mirar la funció anterior - ranking pero modificant el càlcul del score\n",
    "# donar pes al hastags - funció que busqui si els hastags fan match amb les queries\n",
    "# donar pes als likes i als retweets - és el que determinen si el doc és important o no - importancia dins de les xarxes socials.\n",
    "# a partir d'aixo crear una funció per cada cosa\n",
    "# explicar al report com li hem donat un pes a aixo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd1bec-ef79-4f40-9817-7a7a3ab1c580",
   "metadata": {
    "id": "b0fd1bec-ef79-4f40-9817-7a7a3ab1c580"
   },
   "source": [
    "Extract the features that are relevant to build our score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c42229e5-4683-4164-b9db-614b3bdfb8fd",
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1731080989032,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "c42229e5-4683-4164-b9db-614b3bdfb8fd"
   },
   "outputs": [],
   "source": [
    "likes = dict(zip(processed_tweets_df['docId'], processed_tweets_df['Likes']))\n",
    "retweets = dict(zip(processed_tweets_df['docId'], processed_tweets_df['Retweets']))\n",
    "hashtags = dict(zip(processed_tweets_df['docId'], processed_tweets_df['Hashtags']))\n",
    "hashtags_counts = dict(zip(processed_tweets_df['docId'], processed_tweets_df['Hashtags_count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4b33f-1efb-46c7-87bc-dcafa3ba6ed1",
   "metadata": {
    "id": "f5e4b33f-1efb-46c7-87bc-dcafa3ba6ed1"
   },
   "source": [
    "Inspect the data in order to decide which normalization apply for build our score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5172b2a-c8d0-47cc-9403-c94a5cdc9271",
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1731080989032,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "c5172b2a-c8d0-47cc-9403-c94a5cdc9271"
   },
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(df, column):\n",
    "    \"\"\"\n",
    "    Detects outliers in a specified column of a DataFrame using the IQR (Interquartile Range) method.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame containing the data.\n",
    "    column (str): The name of the column in which to detect outliers.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing the rows with outliers in the specified column.\n",
    "    \"\"\"\n",
    "    # Calculate the first (Q1) and third (Q3) quartiles\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    # Calculate the Interquartile Range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the lower and upper limits for outliers\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Filter rows with values outside the limits (outliers)\n",
    "    outliers = df[(df[column] < lower_limit) | (df[column] > upper_limit)]\n",
    "\n",
    "    if not outliers.empty:\n",
    "        print(f\"The column '{column}' contains outliers.\")\n",
    "    else:\n",
    "        print(f\"No outliers found in the column '{column}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e7dd94b9-5a98-4f89-aa15-c655c49954e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1731080989032,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "e7dd94b9-5a98-4f89-aa15-c655c49954e8",
    "outputId": "68734855-11ba-4265-8752-c75418bb53f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stadistics Number of Hashtags\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    48429.000000\n",
       "mean         2.816597\n",
       "std          2.386539\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          3.000000\n",
       "max         25.000000\n",
       "Name: Hashtags_count, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stadistics Likes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    48429.000000\n",
       "mean        17.955419\n",
       "std        242.634042\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          3.000000\n",
       "max      27888.000000\n",
       "Name: Likes, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stadistics Retweets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    48429.000000\n",
       "mean         7.263664\n",
       "std         69.987750\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          2.000000\n",
       "max       6164.000000\n",
       "Name: Retweets, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# score\n",
    "# numero de likes i de retweets normalitzem\n",
    "\n",
    "# per saber quina normalització aplicar\n",
    "print('Stadistics Number of Hashtags')\n",
    "display(processed_tweets_df['Hashtags_count'].describe())\n",
    "\n",
    "print('\\nStadistics Likes')\n",
    "display(processed_tweets_df['Likes'].describe())\n",
    "\n",
    "print('\\nStadistics Retweets')\n",
    "display(processed_tweets_df['Retweets'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4bed7e04-f269-4777-a090-0fcd40beb476",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1731080989033,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "4bed7e04-f269-4777-a090-0fcd40beb476",
    "outputId": "a9c60494-0dcf-479f-f46b-df1b2afccf5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column 'Hashtags_count' contains outliers.\n",
      "The column 'Likes' contains outliers.\n",
      "The column 'Retweets' contains outliers.\n"
     ]
    }
   ],
   "source": [
    "# Display the rows containing outliers\n",
    "detect_outliers_iqr(processed_tweets_df, 'Hashtags_count')\n",
    "detect_outliers_iqr(processed_tweets_df, 'Likes')\n",
    "detect_outliers_iqr(processed_tweets_df, 'Retweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d539543-cfac-46ff-a023-0dd3578f59a1",
   "metadata": {
    "id": "4d539543-cfac-46ff-a023-0dd3578f59a1"
   },
   "source": [
    "Given that your data is highly skewed and contains extreme outliers, the logarithmic transformation is likely the best option for normalization. It will effectively reduce the impact of outliers and compress the wide range of values in both the Likes and Retweets columns, making them more comparable and easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "61fcac14-c628-41c0-b9d0-f153c603c0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_score(likes, retweets, weigh_1, weigh_2):\n",
    "    \n",
    "    log_likes = np.log1p(likes)\n",
    "    log_retweets = np.log1p(retweets)\n",
    "\n",
    "    popularity_score = log_likes * weigh_1 + log_retweets * weigh_2\n",
    "\n",
    "    return popularity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50722927-5df9-4877-b139-5b2787e9ae02",
   "metadata": {
    "id": "50722927-5df9-4877-b139-5b2787e9ae02"
   },
   "source": [
    "Crear la funció que dona el score - tenir el compte Likes_log i  Retweets_log\n",
    "També cal tenir en compte si hi ha match del hashtag amb la query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd967e9-68c1-4b0c-9ae4-85caa38ddcf6",
   "metadata": {
    "id": "0fd967e9-68c1-4b0c-9ae4-85caa38ddcf6"
   },
   "source": [
    "Per poder crear un score en el qual una part estigui basat en el match entre els hashtags i la query primer convertim la columna dels hashtags que ara és un string en una llista, on cada element és un string.\n",
    "\n",
    "REVISAR SI CAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "68035fa0-e158-4df3-9df8-2db5ee7a7c0b",
   "metadata": {
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1731080989910,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "68035fa0-e158-4df3-9df8-2db5ee7a7c0b"
   },
   "outputs": [],
   "source": [
    "processed_tweets_df.loc[:, 'Hashtags'] = processed_tweets_df['Hashtags'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d3a0c829-26f0-44b0-8e48-7e1e07420b5c",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1731080989911,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "d3a0c829-26f0-44b0-8e48-7e1e07420b5c"
   },
   "outputs": [],
   "source": [
    "def process_hashtags(hashtags):\n",
    "\n",
    "    \"\"\"\n",
    "    Processes a hashtag string by removing the '#' symbol, separating words,\n",
    "    converting to lowercase, removing punctuation, and performing stemming.\n",
    "\n",
    "    Parameters:\n",
    "    hashtag (str): The hashtag string to be processed. It should be a string that starts with '#'.\n",
    "\n",
    "    Returns:\n",
    "    str: A processed version of the hashtag w\n",
    "    \"\"\"\n",
    "\n",
    "    processed_hashtags = []\n",
    "\n",
    "    for hashtag in hashtags:\n",
    "        # delete #\n",
    "        hashtag = hashtag[1:]\n",
    "\n",
    "        # separate words in hashtag\n",
    "        hashtag = re.sub(r'(?<!^)(?=[A-Z])', ' ', hashtag)\n",
    "        hashtag = re.sub(r'(?<=_)', ' ', hashtag)\n",
    "\n",
    "        # convert to lower\n",
    "        hashtag = hashtag.lower()\n",
    "\n",
    "        # remove punctuation\n",
    "        hashtag = re.sub(r'[^a-z0-9#@ ]+', '', hashtag)\n",
    "        # delete punctuation\n",
    "        hashtag = re.sub(r'[^\\w\\s]', '', hashtag)\n",
    "\n",
    "        # perform stemming\n",
    "        # divide the text into words\n",
    "        words = hashtag.split()\n",
    "        # define the stemmer\n",
    "        stemmer = PorterStemmer()\n",
    "        hashtag = [stemmer.stem(word) for word in words]\n",
    "\n",
    "        processed_hashtags.append(hashtag)\n",
    "\n",
    "    return processed_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3622832-8826-4f1b-82c4-dd7295036041",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1731080989911,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "a3622832-8826-4f1b-82c4-dd7295036041"
   },
   "outputs": [],
   "source": [
    "def find_matching(hashtags, query, hashtag_count):\n",
    "    \"\"\"\n",
    "    Finds how many words from a processed hashtag match any word from a processed query.\n",
    "\n",
    "    Parameters:\n",
    "    hashtags (list of lists): A list of hashtags, each represented as a list of processed words.\n",
    "    query (list): A list of words from the query to be matched with the hashtags.\n",
    "    hashtag_count (int): The number of hashtags of a record in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of matching words between the hashtags and the query.\n",
    "    \"\"\"\n",
    "\n",
    "    # only if the record has hashtags\n",
    "    if hashtag_count != 0:\n",
    "        score = 0\n",
    "        # process the query and the hashtag\n",
    "        hashtags = process_hashtags(hashtags)\n",
    "        query = process_tweet(query)\n",
    "\n",
    "        # work with sets is more faster\n",
    "        query_set = set(query)\n",
    "\n",
    "        for hashtag in hashtags:\n",
    "            hashtag_set = set(hashtag)\n",
    "\n",
    "            # intersection between hashtag and query\n",
    "            matching_words = hashtag_set.intersection(query_set)\n",
    "\n",
    "            # add the match len\n",
    "            score += len(matching_words)\n",
    "        return score\n",
    "\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "00bac61d-5a5d-4e98-8dc0-04035817707a",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731080989911,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "00bac61d-5a5d-4e98-8dc0-04035817707a"
   },
   "outputs": [],
   "source": [
    "# revisar !!!!!!\n",
    "\n",
    "def our_rank_documents(terms, docs, index, idf, tf, likes, retweets, hashtags, weights):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "\n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "\n",
    "    Returns:\n",
    "    Print the list of ranked documents\n",
    "    \"\"\"\n",
    "\n",
    "    # I'm interested only on the element of the docVector corresponding to the query terms\n",
    "    # The remaining elements would became 0 when multiplied to the query_vector\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) # I call doc_vectors[k] for a nonexistent key k, the key-value pair (k,[0]*len(terms)) will be automatically added to the dictionary\n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms)  # get the frequency of each term in the query.\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        ## Compute tf*idf(normalize TF as done with documents)\n",
    "        query_vector[termIndex]= query_terms_count[term]/ query_norm * idf[term]\n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc_index, (doc, postings) in enumerate(index[term]):\n",
    "\n",
    "            #tf[term][0] will contain the tf of the term \"term\" in the doc 26\n",
    "            if doc in docs:\n",
    "\n",
    "                # obtain the likes and retweets of the doc\n",
    "                number_likes = likes[doc]\n",
    "                number_retweets = retweets[doc]\n",
    "\n",
    "                # popularity \n",
    "                score_popularity = popularity_score(number_likes, number_retweets, weights[0], weights[1])\n",
    "\n",
    "                # revisar que mes afegir - HASHTAGS\n",
    "                \n",
    "                doc_vectors[doc][termIndex] = tf[term][doc_index] * idf[term] + score_popularity\n",
    "\n",
    "    # Calculate the score of each doc\n",
    "    # compute the cosine similarity between queyVector and each docVector:\n",
    "    # HINT: you can use the dot product because in case of normalized vectors it corresponds to the cosine similarity\n",
    "    # see np.dot\n",
    "\n",
    "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "\n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "    result_scores = [x[0] for x in doc_scores]\n",
    "\n",
    "    if len(result_docs) == 0:\n",
    "        print('No results found, try again')\n",
    "        query = input()\n",
    "        docs = search_our_score(query, index)\n",
    "    return result_docs, result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e0114d4e-9b8d-436b-950f-f70f88b3d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_our_score(query, index):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms.\n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = process_tweet(query)\n",
    "    docs = set()\n",
    "    weights = [0.6, 0.4]\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"\n",
    "            term_docs=[posting[0] for posting in index[term]]\n",
    "            docs |= set(term_docs)\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs = our_rank_documents(query, docs, index, idf, tf, likes, retweets, hashtags, weights)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4bb7142f-d23f-4c25-a0df-fa7fbb83e0ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 15989 retrieved documents for the query 'Indian government response to farmers':\n",
      "\n",
      "docId = doc_2727\t score = 32.6245\n",
      "docId = doc_36986\t score = 28.7722\n",
      "docId = doc_5169\t score = 27.2707\n",
      "docId = doc_22724\t score = 27.1208\n",
      "docId = doc_3500\t score = 26.7714\n",
      "docId = doc_16637\t score = 26.3586\n",
      "docId = doc_34869\t score = 23.4724\n",
      "docId = doc_19383\t score = 22.4788\n",
      "docId = doc_27956\t score = 22.3491\n",
      "docId = doc_36881\t score = 21.8793\n",
      "docId = doc_12753\t score = 21.7938\n",
      "docId = doc_32833\t score = 21.1443\n",
      "docId = doc_1353\t score = 20.6167\n",
      "docId = doc_19361\t score = 20.5803\n",
      "docId = doc_25955\t score = 19.8227\n",
      "docId = doc_32295\t score = 19.6152\n",
      "docId = doc_43834\t score = 19.4029\n",
      "docId = doc_39883\t score = 19.2792\n",
      "docId = doc_7778\t score = 18.8642\n",
      "docId = doc_4926\t score = 18.8341\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 15767 retrieved documents for the query 'International support for farmers':\n",
      "\n",
      "docId = doc_19243\t score = 34.8651\n",
      "docId = doc_44945\t score = 30.9662\n",
      "docId = doc_3203\t score = 28.5105\n",
      "docId = doc_27791\t score = 27.9088\n",
      "docId = doc_19325\t score = 24.305\n",
      "docId = doc_38783\t score = 19.8119\n",
      "docId = doc_33881\t score = 18.8055\n",
      "docId = doc_38012\t score = 18.643\n",
      "docId = doc_46695\t score = 18.376\n",
      "docId = doc_29408\t score = 17.9243\n",
      "docId = doc_29001\t score = 17.9042\n",
      "docId = doc_13630\t score = 17.513\n",
      "docId = doc_31312\t score = 17.4205\n",
      "docId = doc_27720\t score = 17.4119\n",
      "docId = doc_37003\t score = 17.2264\n",
      "docId = doc_26650\t score = 16.9791\n",
      "docId = doc_28451\t score = 16.2662\n",
      "docId = doc_37099\t score = 16.2112\n",
      "docId = doc_8193\t score = 16.0922\n",
      "docId = doc_30198\t score = 15.6192\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 14911 retrieved documents for the query 'Demands of farmers' protests':\n",
      "\n",
      "docId = doc_42516\t score = 32.3115\n",
      "docId = doc_9979\t score = 26.9142\n",
      "docId = doc_36441\t score = 26.4598\n",
      "docId = doc_45283\t score = 26.1955\n",
      "docId = doc_36996\t score = 25.5265\n",
      "docId = doc_2727\t score = 23.5451\n",
      "docId = doc_43660\t score = 23.211\n",
      "docId = doc_28694\t score = 22.49\n",
      "docId = doc_14779\t score = 22.4722\n",
      "docId = doc_31702\t score = 21.6023\n",
      "docId = doc_14324\t score = 21.1426\n",
      "docId = doc_37143\t score = 20.3296\n",
      "docId = doc_19633\t score = 20.0306\n",
      "docId = doc_24430\t score = 19.7849\n",
      "docId = doc_37068\t score = 19.5759\n",
      "docId = doc_13630\t score = 18.8882\n",
      "docId = doc_47735\t score = 18.8332\n",
      "docId = doc_45426\t score = 18.2169\n",
      "docId = doc_44034\t score = 18.1717\n",
      "docId = doc_36332\t score = 17.9004\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 15935 retrieved documents for the query 'Police action during farmers protest':\n",
      "\n",
      "docId = doc_30062\t score = 28.6356\n",
      "docId = doc_23286\t score = 26.1465\n",
      "docId = doc_16961\t score = 24.3086\n",
      "docId = doc_3174\t score = 22.0925\n",
      "docId = doc_22796\t score = 22.0911\n",
      "docId = doc_3227\t score = 19.583\n",
      "docId = doc_14625\t score = 19.5047\n",
      "docId = doc_44054\t score = 19.3489\n",
      "docId = doc_24962\t score = 19.2484\n",
      "docId = doc_5807\t score = 18.9938\n",
      "docId = doc_32866\t score = 18.9482\n",
      "docId = doc_47052\t score = 18.4139\n",
      "docId = doc_23037\t score = 18.2479\n",
      "docId = doc_30731\t score = 18.2366\n",
      "docId = doc_15954\t score = 18.231\n",
      "docId = doc_38073\t score = 17.9329\n",
      "docId = doc_6075\t score = 17.8312\n",
      "docId = doc_20344\t score = 17.7918\n",
      "docId = doc_30235\t score = 17.4376\n",
      "docId = doc_4926\t score = 17.416\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 4394 retrieved documents for the query 'Schedules and locations of demonstrations and protests':\n",
      "\n",
      "docId = doc_19010\t score = 37.8816\n",
      "docId = doc_19312\t score = 30.9452\n",
      "docId = doc_20732\t score = 30.1666\n",
      "docId = doc_47409\t score = 29.4172\n",
      "docId = doc_20809\t score = 28.4739\n",
      "docId = doc_37942\t score = 24.3261\n",
      "docId = doc_40237\t score = 23.9625\n",
      "docId = doc_43892\t score = 22.7138\n",
      "docId = doc_45564\t score = 22.082\n",
      "docId = doc_39132\t score = 21.7044\n",
      "docId = doc_19383\t score = 19.8068\n",
      "docId = doc_27956\t score = 19.592\n",
      "docId = doc_20722\t score = 18.8269\n",
      "docId = doc_45516\t score = 17.728\n",
      "docId = doc_44678\t score = 17.6863\n",
      "docId = doc_46560\t score = 17.5678\n",
      "docId = doc_1610\t score = 17.447\n",
      "docId = doc_2319\t score = 17.4224\n",
      "docId = doc_1567\t score = 16.8345\n",
      "docId = doc_3228\t score = 16.7651\n"
     ]
    }
   ],
   "source": [
    "top = 20\n",
    "results = {}  # dictionary to store results for each query\n",
    "\n",
    "# iterate through queries\n",
    "for i, query in enumerate(queries):\n",
    "    # execute the search function\n",
    "    ranked_docs, result_scores = search_our_score(query, index)\n",
    "\n",
    "    # store results in the dictionary\n",
    "    results[f'ranked_docs_q{i+1}'] = ranked_docs\n",
    "    results[f'result_scores_q{i+1}'] = result_scores\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------------------------------')\n",
    "    # print the top documents and their scores\n",
    "\n",
    "    print(f\"\\nTop {top} results out of {len(ranked_docs)} retrieved documents for the query '{query}':\\n\")\n",
    "    for doc_id, score in zip(ranked_docs[:top], result_scores[:top]):\n",
    "        print(f'docId = {doc_id}\\t score = {round(score, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ec0de-a251-4d40-b0c7-5a483f24ddf7",
   "metadata": {
    "id": "3b5ec0de-a251-4d40-b0c7-5a483f24ddf7"
   },
   "source": [
    "- **BM25**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "FPnZi9H_jxxi",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731080989912,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "FPnZi9H_jxxi"
   },
   "outputs": [],
   "source": [
    "def rank_documents_bm25 (terms, docs, index, idf, tf, k1, b, N, doc_length, lavg):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the BM25 weights\n",
    "\n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    k1 -- tunning parameter controling document term frequency scaling\n",
    "    b -- tunning parameter controling the scaling by document length\n",
    "    N -- number of documents\n",
    "    doc_lenght -- dictionary with lenghts of all documents\n",
    "    lavg -- average document length in the whole collection\n",
    "\n",
    "    Returns:\n",
    "    list of ranked documents\n",
    "    scores of the documents\n",
    "    \"\"\"\n",
    "\n",
    "    # I'm interested only on the element of the docVector corresponding to the query terms\n",
    "    # The remaining elements would became 0 when multiplied to the query_vector\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) # I call doc_vectors[k] for a nonexistent key k, the key-value pair (k,[0]*len(terms)) will be automatically added to the dictionary\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        dft = len(index[term]) #in how many documents does it appear\n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc_index, (doc, postings) in enumerate(index[term]):\n",
    "\n",
    "            if doc in docs:\n",
    "                ld = doc_length[doc] #document length\n",
    "                doc_vectors[doc][termIndex] = np.log(N/dft) * (((k1+1)*tf[term][doc_index]) / (k1*((1-b)+b*( ld / lavg ) ) + tf[term][doc_index]))\n",
    "\n",
    "    # Calculate the score of each doc\n",
    "    doc_scores=[[np.sum(curDocVec), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "    result_scores = [x[0] for x in doc_scores]\n",
    "    if len(result_docs) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "\n",
    "    return result_docs, result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "n9x9CkuQlEZS",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731080989912,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "n9x9CkuQlEZS"
   },
   "outputs": [],
   "source": [
    "def search_bm25(query, index, k1, b, N, doc_length, lavg):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain all of the query terms.\n",
    "    So, we will get the list of documents for each query term, and take the intersaction of them.\n",
    "    \"\"\"\n",
    "    query = process_tweet(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"\n",
    "            term_docs = [posting[0] for posting in index[term]]\n",
    "\n",
    "            # docs = docs Intersaction term_docs\n",
    "            if len(docs) == 0:\n",
    "              docs = set(term_docs)\n",
    "            else:\n",
    "              docs.intersaction(set(term_docs))\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs, result_scores = rank_documents_bm25 (query, docs, index, idf, tf, k1, b, N, doc_length, lavg)\n",
    "    return ranked_docs, result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "g0R0uRO_kosj",
   "metadata": {
    "executionInfo": {
     "elapsed": 2356,
     "status": "ok",
     "timestamp": 1731080992260,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "g0R0uRO_kosj"
   },
   "outputs": [],
   "source": [
    "# Ld\n",
    "doc_length = dict()\n",
    "for i, row in processed_tweets_df.iterrows():\n",
    "  doc_length[row['docId']]= len(row['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "SSZYPE73kr4O",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1731080992261,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "SSZYPE73kr4O"
   },
   "outputs": [],
   "source": [
    "# Lavg\n",
    "lavg = 0\n",
    "for length in doc_length.values():\n",
    "  lavg+=length\n",
    "\n",
    "lavg = round(lavg / len(doc_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2mv2Pil7kyOq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2775,
     "status": "ok",
     "timestamp": 1731080995029,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "2mv2Pil7kyOq",
    "outputId": "663d70f4-af0c-4320-eb7c-46a6cdb0d962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "Top 20 results out of 2719 for the searched query Indian government response to farmers:\n",
      "\n",
      "page_id = doc_13543\t score = 6.018461467422177\n",
      "page_id = doc_30422\t score = 5.711082995326188\n",
      "page_id = doc_41848\t score = 5.47864863495953\n",
      "page_id = doc_40125\t score = 5.47864863495953\n",
      "page_id = doc_40124\t score = 5.47864863495953\n",
      "page_id = doc_38240\t score = 5.47864863495953\n",
      "page_id = doc_31710\t score = 5.47864863495953\n",
      "page_id = doc_3116\t score = 5.47864863495953\n",
      "page_id = doc_29545\t score = 5.47864863495953\n",
      "page_id = doc_26363\t score = 5.47864863495953\n",
      "page_id = doc_17769\t score = 5.47864863495953\n",
      "page_id = doc_14237\t score = 5.47864863495953\n",
      "page_id = doc_12228\t score = 5.47864863495953\n",
      "page_id = doc_11484\t score = 5.47864863495953\n",
      "page_id = doc_31188\t score = 5.451518096785867\n",
      "page_id = doc_27778\t score = 5.451518096785867\n",
      "page_id = doc_34728\t score = 5.424654938061487\n",
      "page_id = doc_36211\t score = 4.8267924274395\n",
      "page_id = doc_46211\t score = 4.7309752080362335\n",
      "page_id = doc_42096\t score = 4.7309752080362335\n",
      "\n",
      "======================\n",
      "Top 20 results out of 443 for the searched query International support for farmers:\n",
      "\n",
      "page_id = doc_859\t score = 7.671749011909789\n",
      "page_id = doc_21846\t score = 7.671749011909789\n",
      "page_id = doc_38762\t score = 5.292825659478492\n",
      "page_id = doc_21630\t score = 5.267141544898828\n",
      "page_id = doc_27400\t score = 5.241705497454418\n",
      "page_id = doc_44066\t score = 4.907132967516674\n",
      "page_id = doc_12950\t score = 4.826802064713101\n",
      "page_id = doc_31474\t score = 4.45532336932703\n",
      "page_id = doc_28358\t score = 4.433039688553589\n",
      "page_id = doc_25064\t score = 4.38913442632224\n",
      "page_id = doc_27294\t score = 4.36750631968045\n",
      "page_id = doc_40138\t score = 4.356849957244348\n",
      "page_id = doc_6713\t score = 3.963816363142042\n",
      "page_id = doc_32164\t score = 3.9279957077723493\n",
      "page_id = doc_29112\t score = 3.8919924107560764\n",
      "page_id = doc_48125\t score = 3.86657675462777\n",
      "page_id = doc_6031\t score = 3.8471954175118412\n",
      "page_id = doc_41492\t score = 3.809009855055148\n",
      "page_id = doc_6920\t score = 3.790199929844999\n",
      "page_id = doc_44813\t score = 3.790199929844999\n",
      "\n",
      "======================\n",
      "Top 20 results out of 496 for the searched query Demands of farmers' protests:\n",
      "\n",
      "page_id = doc_15908\t score = 6.570517361197074\n",
      "page_id = doc_17929\t score = 5.510834223927822\n",
      "page_id = doc_43415\t score = 5.140344916805858\n",
      "page_id = doc_887\t score = 4.806303976565441\n",
      "page_id = doc_43810\t score = 4.75883430766109\n",
      "page_id = doc_43799\t score = 4.75883430766109\n",
      "page_id = doc_43790\t score = 4.75883430766109\n",
      "page_id = doc_18273\t score = 4.735449372488309\n",
      "page_id = doc_17894\t score = 4.735449372488309\n",
      "page_id = doc_30921\t score = 4.458639259559197\n",
      "page_id = doc_15930\t score = 4.348069752639702\n",
      "page_id = doc_41953\t score = 4.326322510000587\n",
      "page_id = doc_1940\t score = 4.326322510000587\n",
      "page_id = doc_10445\t score = 4.326322510000587\n",
      "page_id = doc_12705\t score = 4.298524399105498\n",
      "page_id = doc_39659\t score = 4.283474185229341\n",
      "page_id = doc_10879\t score = 4.251162221997042\n",
      "page_id = doc_46147\t score = 4.2096357732472125\n",
      "page_id = doc_10418\t score = 4.2096357732472125\n",
      "page_id = doc_47735\t score = 4.019610058713129\n",
      "\n",
      "======================\n",
      "Top 20 results out of 1448 for the searched query Police action during farmers protest:\n",
      "\n",
      "page_id = doc_32026\t score = 7.876383763879883\n",
      "page_id = doc_7588\t score = 4.590492068489268\n",
      "page_id = doc_14464\t score = 4.5857817738996225\n",
      "page_id = doc_45728\t score = 4.531555522404657\n",
      "page_id = doc_9604\t score = 4.442747882312812\n",
      "page_id = doc_25479\t score = 4.253499225936463\n",
      "page_id = doc_32162\t score = 4.217107789753413\n",
      "page_id = doc_14699\t score = 4.046400831226678\n",
      "page_id = doc_36833\t score = 3.9768369790340747\n",
      "page_id = doc_18802\t score = 3.9354429173039334\n",
      "page_id = doc_47283\t score = 3.93264915034554\n",
      "page_id = doc_14625\t score = 3.85044955227455\n",
      "page_id = doc_11674\t score = 3.717808658289146\n",
      "page_id = doc_22518\t score = 3.5268791993420328\n",
      "page_id = doc_33473\t score = 3.427697617212414\n",
      "page_id = doc_34650\t score = 3.395930871033868\n",
      "page_id = doc_32988\t score = 3.365075086055999\n",
      "page_id = doc_37797\t score = 3.348074313656878\n",
      "page_id = doc_31516\t score = 3.348074313656878\n",
      "page_id = doc_25399\t score = 3.348074313656878\n",
      "\n",
      "======================\n",
      "Top 20 results out of 16 for the searched query Schedules and locations of demonstrations and protests:\n",
      "\n",
      "page_id = doc_43892\t score = 8.99339161121647\n",
      "page_id = doc_46453\t score = 6.196198047800415\n",
      "page_id = doc_45516\t score = 5.970368506194933\n",
      "page_id = doc_26556\t score = 3.5142609624381103\n",
      "page_id = doc_3228\t score = 3.188162113127597\n",
      "page_id = doc_20809\t score = 2.5712504122679753\n",
      "page_id = doc_20722\t score = 2.5712504122679753\n",
      "page_id = doc_48234\t score = 2.1801013437532037\n",
      "page_id = doc_23067\t score = 2.0809524371121184\n",
      "page_id = doc_47409\t score = 2.0275201857865777\n",
      "page_id = doc_47369\t score = 2.0275201857865777\n",
      "page_id = doc_46560\t score = 2.0275201857865777\n",
      "page_id = doc_9358\t score = 1.8702769902614576\n",
      "page_id = doc_45381\t score = 1.6076152887049262\n",
      "page_id = doc_48029\t score = 1.5361067711391412\n",
      "page_id = doc_32308\t score = 1.4526786813907067\n"
     ]
    }
   ],
   "source": [
    "ranked_docs = [0]*5\n",
    "result_scores = [0]*5\n",
    "k1 = 2\n",
    "b = 0.5\n",
    "N = len(relevance_features_df)\n",
    "\n",
    "i = 0\n",
    "for query in queries:\n",
    "\n",
    "  ranked_docs[i], result_scores[i] = search_bm25(query, index, k1, b, N, doc_length, lavg)\n",
    "  top = 20\n",
    "  print(\"\\n======================\\nTop {} results out of {} for the searched query {}:\\n\".format(top, len(ranked_docs[i]), query))\n",
    "\n",
    "  j=0\n",
    "  for j in range(len(ranked_docs[i])):\n",
    "    if (j < top):\n",
    "      print(\"page_id = {}\\t score = {}\".format(ranked_docs[i][j], result_scores[i][j]))\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2dd519-1307-4f4c-be0b-43b6553650b2",
   "metadata": {
    "id": "9e2dd519-1307-4f4c-be0b-43b6553650b2"
   },
   "source": [
    "Explain how the ranking differs when using TF-IDF and BM25 and think about the pros and cons of using them. Regarding your own score, justify the choice of the score (pros and cons). The only constraint you have is that the score needs to involve the tweets information regarding the popularity over the social network (number of likes, number of tweets, number of comments, etc…)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf2af8-f8ae-4cee-a76b-fe52bb9368db",
   "metadata": {
    "id": "bdbf2af8-f8ae-4cee-a76b-fe52bb9368db"
   },
   "source": [
    "**2. Return a top-20 list of documents for each of the 5 queries, using word2vec + cosine similarity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "BONwvktjoplY",
   "metadata": {
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1731080995434,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "BONwvktjoplY"
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "yw1DSgLTqOIU",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1731080995854,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "yw1DSgLTqOIU"
   },
   "outputs": [],
   "source": [
    "lines = processed_tweets_df['Tweet']\n",
    "clean_tweets = []\n",
    "for line in lines:\n",
    "\n",
    "  clean_tweets.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "525Sydwwqk3K",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731080995854,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "525Sydwwqk3K"
   },
   "outputs": [],
   "source": [
    "sentences = clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "kRaYn2Ncn4a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731080995855,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "kRaYn2Ncn4a6"
   },
   "outputs": [],
   "source": [
    "def search_word2vec(query, index, vector_size):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain all of the query terms.\n",
    "    So, we will get the list of documents for each query term, and take the intersaction of them.\n",
    "    \"\"\"\n",
    "    query = process_tweet(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"\n",
    "            term_docs = [posting[0] for posting in index[term]]\n",
    "\n",
    "            # docs = docs Intersaction term_docs\n",
    "            if len(docs) == 0:\n",
    "              docs = set(term_docs)\n",
    "            else:\n",
    "              docs.intersaction(set(term_docs))\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs, result_scores = rank_documents_word2vec (query, docs, vector_size)\n",
    "    return ranked_docs, result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "kJpqpifyoFcx",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731080995855,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "kJpqpifyoFcx"
   },
   "outputs": [],
   "source": [
    "def rank_documents_word2vec (terms, docs, v_size):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on word2vec\n",
    "\n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "\n",
    "    Returns:\n",
    "    list of ranked documents\n",
    "    scores of the documents\n",
    "    \"\"\"\n",
    "    tweet2vec = {'docId': docs}\n",
    "\n",
    "    # Computing a vector for each word\n",
    "    sentence = []\n",
    "    for i, row in processed_tweets_df.iterrows(): # for each tweet\n",
    "      sentences.append(row['Tweet'])\n",
    "    model = Word2Vec(sentences, vector_size=100)\n",
    "\n",
    "    for i, row in processed_tweets_df.iterrows():\n",
    "      if row['docId'] in docs:\n",
    "        doc_vector = [model.wv[word] for word in row['Tweet']]\n",
    "        tweet2vec[row['docId']]=np.mean(doc_vector, axis=0)\n",
    "\n",
    "    # Computing the vector for the query\n",
    "    query2vec = [model.wv[word] for word in query if word in model.wv.key_to_index]\n",
    "    query2vec = np.mean(query2vec, axis=0)\n",
    "\n",
    "    # Calculate the score of each doc\n",
    "    doc_scores=[[np.dot(curDocVec, query2vec), doc] for doc, curDocVec in tweet2vec.items() if doc in docs]\n",
    "    doc_scores.sort(reverse=True)\n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "    result_scores = [x[0] for x in doc_scores]\n",
    "    if len(result_docs) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "\n",
    "    return result_docs, result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "LJzYs4LOnviI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261422,
     "status": "ok",
     "timestamp": 1731081257269,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "LJzYs4LOnviI",
    "outputId": "df3bbc9d-3612-42dc-cc8b-f0c1b258cccb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "Top 20 results out of 2719 for the searched query Indian government response to farmers:\n",
      "\n",
      "page_id = doc_36886\t score = 11.055171966552734\n",
      "page_id = doc_28972\t score = 11.048758506774902\n",
      "page_id = doc_8866\t score = 11.048734664916992\n",
      "page_id = doc_1672\t score = 11.022855758666992\n",
      "page_id = doc_26898\t score = 11.0186185836792\n",
      "page_id = doc_32181\t score = 11.013521194458008\n",
      "page_id = doc_1670\t score = 11.002734184265137\n",
      "page_id = doc_42913\t score = 10.989734649658203\n",
      "page_id = doc_45348\t score = 10.984062194824219\n",
      "page_id = doc_1265\t score = 10.975194931030273\n",
      "page_id = doc_1242\t score = 10.975194931030273\n",
      "page_id = doc_1128\t score = 10.975194931030273\n",
      "page_id = doc_38085\t score = 10.970766067504883\n",
      "page_id = doc_27384\t score = 10.967411041259766\n",
      "page_id = doc_22895\t score = 10.965227127075195\n",
      "page_id = doc_8073\t score = 10.956025123596191\n",
      "page_id = doc_5511\t score = 10.955581665039062\n",
      "page_id = doc_43814\t score = 10.954549789428711\n",
      "page_id = doc_35055\t score = 10.941516876220703\n",
      "page_id = doc_11845\t score = 10.935935974121094\n",
      "\n",
      "======================\n",
      "Top 20 results out of 443 for the searched query International support for farmers:\n",
      "\n",
      "page_id = doc_9046\t score = 12.565213203430176\n",
      "page_id = doc_32923\t score = 12.541956901550293\n",
      "page_id = doc_37775\t score = 12.488123893737793\n",
      "page_id = doc_40758\t score = 12.46833324432373\n",
      "page_id = doc_33881\t score = 12.467857360839844\n",
      "page_id = doc_6713\t score = 12.463125228881836\n",
      "page_id = doc_6883\t score = 12.437840461730957\n",
      "page_id = doc_43188\t score = 12.43190860748291\n",
      "page_id = doc_44140\t score = 12.42852783203125\n",
      "page_id = doc_36205\t score = 12.403127670288086\n",
      "page_id = doc_42972\t score = 12.388436317443848\n",
      "page_id = doc_31474\t score = 12.386405944824219\n",
      "page_id = doc_45070\t score = 12.382579803466797\n",
      "page_id = doc_40846\t score = 12.368718147277832\n",
      "page_id = doc_4107\t score = 12.355384826660156\n",
      "page_id = doc_3447\t score = 12.35470199584961\n",
      "page_id = doc_6920\t score = 12.33820915222168\n",
      "page_id = doc_13718\t score = 12.328512191772461\n",
      "page_id = doc_24734\t score = 12.32713508605957\n",
      "page_id = doc_31202\t score = 12.325833320617676\n",
      "\n",
      "======================\n",
      "Top 20 results out of 496 for the searched query Demands of farmers' protests:\n",
      "\n",
      "page_id = doc_10292\t score = 13.98745346069336\n",
      "page_id = doc_36885\t score = 13.921184539794922\n",
      "page_id = doc_36890\t score = 13.866518020629883\n",
      "page_id = doc_36628\t score = 13.866518020629883\n",
      "page_id = doc_40148\t score = 13.801536560058594\n",
      "page_id = doc_38712\t score = 13.77944564819336\n",
      "page_id = doc_36607\t score = 13.760322570800781\n",
      "page_id = doc_10875\t score = 13.746536254882812\n",
      "page_id = doc_10879\t score = 13.720422744750977\n",
      "page_id = doc_36735\t score = 13.714688301086426\n",
      "page_id = doc_10296\t score = 13.653546333312988\n",
      "page_id = doc_16918\t score = 13.647793769836426\n",
      "page_id = doc_10621\t score = 13.63412094116211\n",
      "page_id = doc_18128\t score = 13.630844116210938\n",
      "page_id = doc_10418\t score = 13.62862777709961\n",
      "page_id = doc_17340\t score = 13.628403663635254\n",
      "page_id = doc_10573\t score = 13.615418434143066\n",
      "page_id = doc_10002\t score = 13.615418434143066\n",
      "page_id = doc_30921\t score = 13.601601600646973\n",
      "page_id = doc_9028\t score = 13.5995454788208\n",
      "\n",
      "======================\n",
      "Top 20 results out of 1448 for the searched query Police action during farmers protest:\n",
      "\n",
      "page_id = doc_1719\t score = 15.399481773376465\n",
      "page_id = doc_13141\t score = 15.072508811950684\n",
      "page_id = doc_33389\t score = 15.067752838134766\n",
      "page_id = doc_14177\t score = 15.067509651184082\n",
      "page_id = doc_25399\t score = 15.047507286071777\n",
      "page_id = doc_45728\t score = 15.044807434082031\n",
      "page_id = doc_14588\t score = 15.02332878112793\n",
      "page_id = doc_33565\t score = 14.976696014404297\n",
      "page_id = doc_13416\t score = 14.973689079284668\n",
      "page_id = doc_24778\t score = 14.960042953491211\n",
      "page_id = doc_18783\t score = 14.959754943847656\n",
      "page_id = doc_1670\t score = 14.951337814331055\n",
      "page_id = doc_33014\t score = 14.945088386535645\n",
      "page_id = doc_3360\t score = 14.938640594482422\n",
      "page_id = doc_21520\t score = 14.91290283203125\n",
      "page_id = doc_14082\t score = 14.907668113708496\n",
      "page_id = doc_12234\t score = 14.881692886352539\n",
      "page_id = doc_12233\t score = 14.881692886352539\n",
      "page_id = doc_14502\t score = 14.8801908493042\n",
      "page_id = doc_14185\t score = 14.87956714630127\n",
      "\n",
      "======================\n",
      "Top 20 results out of 16 for the searched query Schedules and locations of demonstrations and protests:\n",
      "\n",
      "page_id = doc_32308\t score = 15.621424674987793\n",
      "page_id = doc_43892\t score = 15.620306015014648\n",
      "page_id = doc_48029\t score = 15.35289478302002\n",
      "page_id = doc_3228\t score = 15.343032836914062\n",
      "page_id = doc_23067\t score = 15.131789207458496\n",
      "page_id = doc_9358\t score = 15.055767059326172\n",
      "page_id = doc_47409\t score = 14.94866943359375\n",
      "page_id = doc_47369\t score = 14.94866943359375\n",
      "page_id = doc_46560\t score = 14.94866943359375\n",
      "page_id = doc_20809\t score = 14.790533065795898\n",
      "page_id = doc_20722\t score = 14.790533065795898\n",
      "page_id = doc_48234\t score = 14.72847843170166\n",
      "page_id = doc_26556\t score = 14.430363655090332\n",
      "page_id = doc_46453\t score = 14.128853797912598\n",
      "page_id = doc_45381\t score = 14.075575828552246\n",
      "page_id = doc_45516\t score = 13.778241157531738\n"
     ]
    }
   ],
   "source": [
    "ranked_docs = [0]*5\n",
    "result_scores = [0]*5\n",
    "k1 = 2\n",
    "b = 0.5\n",
    "N = len(relevance_features_df)\n",
    "\n",
    "i = 0\n",
    "for query in queries:\n",
    "\n",
    "  ranked_docs[i], result_scores[i] = search_word2vec(query, index, 100)\n",
    "  top = 20\n",
    "  print(\"\\n======================\\nTop {} results out of {} for the searched query {}:\\n\".format(top, len(ranked_docs[i]), query))\n",
    "\n",
    "  j=0\n",
    "  for j in range(len(ranked_docs[i])):\n",
    "    if (j < top):\n",
    "      print(\"page_id = {}\\t score = {}\".format(ranked_docs[i][j], result_scores[i][j]))\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e4316-adf7-49f7-a123-18c453f3565d",
   "metadata": {
    "id": "576e4316-adf7-49f7-a123-18c453f3565d"
   },
   "source": [
    "**3. Can you imagine a better representation than word2vec? Justify your answer. (HINT - what about Doc2vec? Sentence2vec? Which are the pros and cons.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RIu-f6ccfwGE",
   "metadata": {
    "id": "RIu-f6ccfwGE"
   },
   "source": [
    "Transformer-based embeddings, such as those produced by models like BERT (Bidirectional\n",
    "Encoder Representations from Transformers) or GPT (Generative Pre-trained Transformer),\n",
    "have transformed the field of natural language processing. They offer significant\n",
    "advancements over traditional embeddings like Word2Vec, Doc2Vec, and Sentence2Vec.\n",
    "While the use of transformer-based embeddings for information retrieval and ranking tasks offers numerous improvements, it also introduces certain complexities compared to traditional embeddings.\n",
    "\n",
    "Improvements:\n",
    "\n",
    "* Contextual Awareness: Transformers capture the context of words by considering their surrounding words in the text, leading to a deeper understanding of word meanings and nuances. This significantly enhances retrieval accuracy.\n",
    "* Semantic Matching: The ability to understand the specific context in which a word appears allows transformers to identify synonyms, antonyms, and other contextually related terms, thus improving semantic matching.\n",
    "* Multi-modal Capability: They can handle multi-modal inputs, such as text, images, and audio, enhancing their versatility across different types of data.\n",
    "* Extensive Training: Since transformers are trained on large-scale datasets, they are more robust and can handle a broad range of topics and languages effectively.\n",
    "\n",
    "Complexities:\n",
    "\n",
    "* High Computational Requirements: Transformers demand significant computational resources for inference, which can pose challenges for real-time or large-scale retrieval tasks.\n",
    "* Deployment Challenges: Due to their large model sizes, deploying transformer-based systems can be cumbersome and requires considerable memory and storage capacity.\n",
    "* Increased Latency: The inherent complexity of these models can lead to delays in the retrieval process, making them less ideal for time-sensitive applications.\n",
    "* Data and Resource Intensive: Leveraging transformers effectively often requires access to large datasets, pre-trained models, and substantial computational power, which can be prohibitive.\n",
    "\n",
    "Despite the substantial improvements in contextual and semantic understanding offered by transformer-based embeddings—making them ideal for enhancing retrieval outcomes across diverse applications—their high computational demands, large size, and complexity can hinder smooth integration. Thus, whether to use traditional embeddings like Word2Vec or transformer-based models should be determined by the specific requirements and resource availability of the intended retrieval application"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
