{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f29239-b610-4297-a58e-b64b68342580",
   "metadata": {
    "id": "c2f29239-b610-4297-a58e-b64b68342580"
   },
   "source": [
    "## IRWA Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c48446-68e3-4a1d-9b09-4b9c7507e864",
   "metadata": {
    "id": "95c48446-68e3-4a1d-9b09-4b9c7507e864"
   },
   "source": [
    "#### Load Python packages\n",
    "Let's first import all the packages that we will need during the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04627a52-701d-4a26-9b6a-198598094921",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10216,
     "status": "ok",
     "timestamp": 1731080919532,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "04627a52-701d-4a26-9b6a-198598094921",
    "outputId": "a064b957-b035-4d3f-c8ee-c3cbe1afde8f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bertamitjavilapita/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bertamitjavilapita/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9d42f597-1dc8-4884-8094-07b3da6ca248",
   "metadata": {
    "executionInfo": {
     "elapsed": 2595,
     "status": "ok",
     "timestamp": 1731080922123,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "9d42f597-1dc8-4884-8094-07b3da6ca248"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "import time\n",
    "import re\n",
    "from collections import Counter\n",
    "import statistics\n",
    "import json\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import ast\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import rank_bm25\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f89a0-85db-463a-b92a-76c49b559be6",
   "metadata": {
    "id": "1a7f89a0-85db-463a-b92a-76c49b559be6"
   },
   "source": [
    "#### Load data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dujpjqneb5Zv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23048,
     "status": "ok",
     "timestamp": 1731080945163,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "dujpjqneb5Zv",
    "outputId": "8a202533-b604-4f9b-dc9f-ae074d53d237"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc6f0b1-38b0-49ab-92f4-6bfdbaca49f4",
   "metadata": {
    "id": "bbc6f0b1-38b0-49ab-92f4-6bfdbaca49f4"
   },
   "source": [
    "**Data:** we import the pickle, i.e. the serialized data from create_index_tfidf from part 2. We need need term frequencies, document frequencies, the idf values and index for each term in the collection. And dataset of processed tweets that contains the following information for each tweet: Tweet, Date, Hashtags, Hashtags_count, Likes, Retweets, Url, and docId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f55439d0-1614-4c8f-b127-741f33ef448b",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1731080945163,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "f55439d0-1614-4c8f-b127-741f33ef448b"
   },
   "outputs": [],
   "source": [
    "doc_path = '/content/drive/MyDrive/PROJECT IRWA/Part 2/Data/'\n",
    "doc_path = '/Users/bertamitjavilapita/Desktop/BERTA/UPF/4RT/IRWA/PROJECT/Part 2/Data/'\n",
    "# lo load the serialized data for future use\n",
    "def load_serialized_data(filepath=\"index_data.pkl\"):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        index, tf, df, idf = pickle.load(f)\n",
    "    return index, tf, df, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3db28861-5dc4-4ca9-ae53-52b58986192d",
   "metadata": {
    "executionInfo": {
     "elapsed": 7614,
     "status": "ok",
     "timestamp": 1731080952773,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "3db28861-5dc4-4ca9-ae53-52b58986192d"
   },
   "outputs": [],
   "source": [
    "# load the serialized data from the file for future use\n",
    "index, tf, df, idf = load_serialized_data(filepath=doc_path + \"index_data.pkl\")\n",
    "processed_tweets_df = pd.read_csv(doc_path + 'processed_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1467cc95-a293-4a86-9a4c-bc422ffeed50",
   "metadata": {
    "id": "1467cc95-a293-4a86-9a4c-bc422ffeed50"
   },
   "source": [
    "### Part 3: Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e014c35-7b3b-4cb4-94dc-7999be8bb72b",
   "metadata": {
    "id": "0e014c35-7b3b-4cb4-94dc-7999be8bb72b"
   },
   "source": [
    "**Ranking score: Given a query, we want to get the top-20 documents related to the query.**\n",
    "\n",
    "Queries definition:\n",
    "- \"Indian government response to farmers\"\n",
    "- \"International support for farmers\"\n",
    "- \"Demands of farmers' protests\"\n",
    "- \"Police action during farmers protest\"\n",
    "- \"Schedules and locations of demonstrations and protests\"\n",
    "\n",
    "**GOAL: Find all the documents that contain all the words in the query and sort them by their relevance with regard to the query.**\n",
    "\n",
    "**SCORE:**\n",
    "\n",
    "**1. You’re asked to provide 2 different ways of ranking:**\n",
    "- **TF-IDF + cosine similarity: Classical scoring, we have also seen during the practical labs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4bf0051e-8fd2-46c0-b1e7-42909c9d0c27",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1731080952775,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "4bf0051e-8fd2-46c0-b1e7-42909c9d0c27"
   },
   "outputs": [],
   "source": [
    "# definition of our queries\n",
    "queries = ['Indian government response to farmers',\n",
    "           'International support for farmers',\n",
    "           \"Demands of farmers' protests\",\n",
    "           'Police action during farmers protest',\n",
    "           'Schedules and locations of demonstrations and protests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d57f8674-5a5e-40ee-b24a-570df9ee3327",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1731080952776,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "d57f8674-5a5e-40ee-b24a-570df9ee3327"
   },
   "outputs": [],
   "source": [
    "# function from part 1 to process tweets\n",
    "def process_tweet(tweet):\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess the tweet removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "\n",
    "    Argument:\n",
    "    line -- string (tweet) to be preprocessed\n",
    "\n",
    "    Returns:\n",
    "    tweet - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer() # define the stemmer\n",
    "    stop_words = set(stopwords.words(\"english\")) # define the stopwords\n",
    "    tweet =  tweet.lower() # transform the line to lowercase\n",
    "    tweet = tweet.replace('\\\\n', '') # remove newline characters\n",
    "    tweet = ' '.join(tweet.split()) # remove extra whitespaces\n",
    "    tweet = re.sub(r'\\S*https?:\\S*', '', tweet) # delete URLs on the tweet because we won't be able to access to them\n",
    "    tweet.strip() # remove spaces at first and at the end of a message\n",
    "    tweet = re.sub(r' ?#\\S+', '', tweet) # remove word that is with the hastag - hastag is saved separately\n",
    "    tweet = re.sub(r'[^a-z0-9#@ ]+', '', tweet) # remove punctuation\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet) # delete punctuation\n",
    "    tweet = tweet.split() # tokenize the text to get a list of terms\n",
    "    tweet = [word for word in tweet if word not in stop_words] # eliminate the stopwords\n",
    "    tweet = [stemmer.stem(word) for word in tweet] # perform stemming\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f24326a1-f69c-4b69-a875-2ba1ecc229aa",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1731080952776,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "f24326a1-f69c-4b69-a875-2ba1ecc229aa"
   },
   "outputs": [],
   "source": [
    "def rank_documents(terms, docs, index, idf, tf):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "\n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "\n",
    "    Returns:\n",
    "    Print the list of ranked documents\n",
    "    \"\"\"\n",
    "\n",
    "    # I'm interested only on the element of the docVector corresponding to the query terms\n",
    "    # The remaining elements would became 0 when multiplied to the query_vector\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) # I call doc_vectors[k] for a nonexistent key k, the key-value pair (k,[0]*len(terms)) will be automatically added to the dictionary\n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms)  # get the frequency of each term in the query.\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        ## Compute tf*idf(normalize TF as done with documents)\n",
    "        query_vector[termIndex]= query_terms_count[term]/ query_norm * idf[term]\n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc_index, (doc, postings) in enumerate(index[term]):\n",
    "\n",
    "            #tf[term][0] will contain the tf of the term \"term\" in the doc 26\n",
    "            if doc in docs:\n",
    "                doc_vectors[doc][termIndex] = tf[term][doc_index] * idf[term]  # TODO: check if multiply for idf\n",
    "\n",
    "    # Calculate the score of each doc\n",
    "    # compute the cosine similarity between queyVector and each docVector:\n",
    "    # HINT: you can use the dot product because in case of normalized vectors it corresponds to the cosine similarity\n",
    "    # see np.dot\n",
    "\n",
    "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "\n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "    result_scores = [x[0] for x in doc_scores]\n",
    "\n",
    "    if len(result_docs) == 0:\n",
    "        print('No results found, try again')\n",
    "        query = input()\n",
    "        docs = search_tf_idf(query, index)\n",
    "    return result_docs, result_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c1ac0a5-dc0a-4b09-b3fd-30eab1fd2d64",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1731080952777,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "2c1ac0a5-dc0a-4b09-b3fd-30eab1fd2d64"
   },
   "outputs": [],
   "source": [
    "def search_tf_idf(query, index):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms.\n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = process_tweet(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"\n",
    "            term_docs=[posting[0] for posting in index[term]]\n",
    "            docs |= set(term_docs)\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs = rank_documents(query, docs, index, idf, tf)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de3b3341-8570-452b-bec9-550cc93387d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36264,
     "status": "ok",
     "timestamp": 1731080989030,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "de3b3341-8570-452b-bec9-550cc93387d1",
    "outputId": "1094ab82-7d39-4522-8d79-54213128eb6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 15989 retrieved documents for the query 'Indian government response to farmers':\n",
      "\n",
      "docId = doc_3234\t score = 11.8045\n",
      "docId = doc_27784\t score = 9.5898\n",
      "docId = doc_38114\t score = 9.5064\n",
      "docId = doc_38045\t score = 7.8308\n",
      "docId = doc_33082\t score = 7.8308\n",
      "docId = doc_41021\t score = 7.6648\n",
      "docId = doc_13543\t score = 7.5804\n",
      "docId = doc_7288\t score = 7.2119\n",
      "docId = doc_1353\t score = 7.0977\n",
      "docId = doc_39288\t score = 6.7811\n",
      "docId = doc_32344\t score = 6.7811\n",
      "docId = doc_24570\t score = 6.7811\n",
      "docId = doc_24061\t score = 6.7811\n",
      "docId = doc_17249\t score = 6.7811\n",
      "docId = doc_34963\t score = 6.6396\n",
      "docId = doc_37157\t score = 6.5963\n",
      "docId = doc_47642\t score = 6.3002\n",
      "docId = doc_2453\t score = 6.065\n",
      "docId = doc_19626\t score = 6.065\n",
      "docId = doc_16612\t score = 6.065\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 15767 retrieved documents for the query 'International support for farmers':\n",
      "\n",
      "docId = doc_859\t score = 10.9298\n",
      "docId = doc_21846\t score = 10.9298\n",
      "docId = doc_12950\t score = 9.6171\n",
      "docId = doc_38762\t score = 8.9963\n",
      "docId = doc_27400\t score = 8.9963\n",
      "docId = doc_21630\t score = 8.9963\n",
      "docId = doc_6713\t score = 8.0471\n",
      "docId = doc_28710\t score = 7.4676\n",
      "docId = doc_42972\t score = 7.3461\n",
      "docId = doc_31474\t score = 7.3461\n",
      "docId = doc_28358\t score = 7.3461\n",
      "docId = doc_27294\t score = 7.3461\n",
      "docId = doc_25064\t score = 7.3461\n",
      "docId = doc_17785\t score = 7.3461\n",
      "docId = doc_44066\t score = 6.9125\n",
      "docId = doc_25041\t score = 6.7455\n",
      "docId = doc_42502\t score = 6.57\n",
      "docId = doc_6920\t score = 6.3614\n",
      "docId = doc_6031\t score = 6.3614\n",
      "docId = doc_48125\t score = 6.3614\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 14911 retrieved documents for the query 'Demands of farmers' protests':\n",
      "\n",
      "docId = doc_15908\t score = 12.1176\n",
      "docId = doc_43415\t score = 8.5684\n",
      "docId = doc_11006\t score = 7.7504\n",
      "docId = doc_17929\t score = 7.5711\n",
      "docId = doc_41953\t score = 6.9967\n",
      "docId = doc_39659\t score = 6.9967\n",
      "docId = doc_1940\t score = 6.9967\n",
      "docId = doc_15930\t score = 6.9967\n",
      "docId = doc_10445\t score = 6.9967\n",
      "docId = doc_18128\t score = 6.937\n",
      "docId = doc_887\t score = 6.5562\n",
      "docId = doc_43810\t score = 6.5562\n",
      "docId = doc_43799\t score = 6.5562\n",
      "docId = doc_43790\t score = 6.5562\n",
      "docId = doc_18273\t score = 6.5562\n",
      "docId = doc_17894\t score = 6.5562\n",
      "docId = doc_28839\t score = 6.3952\n",
      "docId = doc_30921\t score = 6.3225\n",
      "docId = doc_43437\t score = 6.0588\n",
      "docId = doc_12672\t score = 6.0588\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 15935 retrieved documents for the query 'Police action during farmers protest':\n",
      "\n",
      "docId = doc_24374\t score = 11.4668\n",
      "docId = doc_13980\t score = 11.4668\n",
      "docId = doc_32026\t score = 10.1775\n",
      "docId = doc_5491\t score = 7.0523\n",
      "docId = doc_34650\t score = 6.8573\n",
      "docId = doc_14464\t score = 6.8367\n",
      "docId = doc_17561\t score = 6.8188\n",
      "docId = doc_33549\t score = 6.6209\n",
      "docId = doc_33540\t score = 6.6209\n",
      "docId = doc_32143\t score = 6.6209\n",
      "docId = doc_31632\t score = 6.6209\n",
      "docId = doc_18542\t score = 6.6209\n",
      "docId = doc_32162\t score = 6.2327\n",
      "docId = doc_41805\t score = 6.2242\n",
      "docId = doc_11674\t score = 5.9814\n",
      "docId = doc_18802\t score = 5.9385\n",
      "docId = doc_8324\t score = 5.8725\n",
      "docId = doc_41801\t score = 5.7637\n",
      "docId = doc_33548\t score = 5.7334\n",
      "docId = doc_33539\t score = 5.7334\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 4394 retrieved documents for the query 'Schedules and locations of demonstrations and protests':\n",
      "\n",
      "docId = doc_43892\t score = 22.7138\n",
      "docId = doc_46453\t score = 16.0613\n",
      "docId = doc_45516\t score = 16.0613\n",
      "docId = doc_44233\t score = 13.193\n",
      "docId = doc_45111\t score = 11.9591\n",
      "docId = doc_45564\t score = 11.496\n",
      "docId = doc_9157\t score = 10.419\n",
      "docId = doc_19010\t score = 10.419\n",
      "docId = doc_2192\t score = 9.7347\n",
      "docId = doc_17302\t score = 9.7347\n",
      "docId = doc_16783\t score = 9.7347\n",
      "docId = doc_3228\t score = 9.6849\n",
      "docId = doc_26556\t score = 9.6849\n",
      "docId = doc_41207\t score = 9.5388\n",
      "docId = doc_19312\t score = 9.5388\n",
      "docId = doc_43347\t score = 9.1338\n",
      "docId = doc_42936\t score = 8.7763\n",
      "docId = doc_38629\t score = 8.7295\n",
      "docId = doc_38189\t score = 8.7295\n",
      "docId = doc_20809\t score = 8.2594\n"
     ]
    }
   ],
   "source": [
    "top = 20\n",
    "results = {}  # dictionary to store results for each query\n",
    "\n",
    "# iterate through queries\n",
    "for i, query in enumerate(queries):\n",
    "    # execute the search function\n",
    "    ranked_docs, result_scores = search_tf_idf(query, index)\n",
    "\n",
    "    # store results in the dictionary\n",
    "    results[f'ranked_docs_q{i+1}'] = ranked_docs\n",
    "    results[f'result_scores_q{i+1}'] = result_scores\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------------------------------')\n",
    "    # print the top documents and their scores\n",
    "\n",
    "    print(f\"\\nTop {top} results out of {len(ranked_docs)} retrieved documents for the query '{query}':\\n\")\n",
    "    for doc_id, score in zip(ranked_docs[:top], result_scores[:top]):\n",
    "        print(f'docId = {doc_id}\\t score = {round(score, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b5f75f-5d88-4104-bf68-fd488735f9d0",
   "metadata": {
    "id": "62b5f75f-5d88-4104-bf68-fd488735f9d0"
   },
   "source": [
    "- **Your-Score + cosine similarity: Here the task is to create a new score, and it’s up to you to create a new one.**\n",
    "ELIMINARLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd1bec-ef79-4f40-9817-7a7a3ab1c580",
   "metadata": {
    "id": "b0fd1bec-ef79-4f40-9817-7a7a3ab1c580"
   },
   "source": [
    "Extract the features that are relevant to build our score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec40effe-1c4f-466d-affb-cd3192a8332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_features_df = processed_tweets_df[['docId', 'Hashtags', 'Hashtags_count', 'Likes', 'Retweets']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4b33f-1efb-46c7-87bc-dcafa3ba6ed1",
   "metadata": {
    "id": "f5e4b33f-1efb-46c7-87bc-dcafa3ba6ed1"
   },
   "source": [
    "Inspect the data in order to decide which normalization apply for build our score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5172b2a-c8d0-47cc-9403-c94a5cdc9271",
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1731080989032,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "c5172b2a-c8d0-47cc-9403-c94a5cdc9271"
   },
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(df, column):\n",
    "    \"\"\"\n",
    "    Detects outliers in a specified column of a DataFrame using the IQR (Interquartile Range) method.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame containing the data.\n",
    "    column (str): The name of the column in which to detect outliers.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing the rows with outliers in the specified column.\n",
    "    \"\"\"\n",
    "    # Calculate the first (Q1) and third (Q3) quartiles\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    # Calculate the Interquartile Range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the lower and upper limits for outliers\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Filter rows with values outside the limits (outliers)\n",
    "    outliers = df[(df[column] < lower_limit) | (df[column] > upper_limit)]\n",
    "\n",
    "    if not outliers.empty:\n",
    "        print(f\"The column '{column}' contains outliers.\")\n",
    "    else:\n",
    "        print(f\"No outliers found in the column '{column}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e7dd94b9-5a98-4f89-aa15-c655c49954e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1731080989032,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "e7dd94b9-5a98-4f89-aa15-c655c49954e8",
    "outputId": "68734855-11ba-4265-8752-c75418bb53f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stadistics Number of Hashtags\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    48429.000000\n",
       "mean         2.816597\n",
       "std          2.386539\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          3.000000\n",
       "max         25.000000\n",
       "Name: Hashtags_count, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stadistics Likes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    48429.000000\n",
       "mean        17.955419\n",
       "std        242.634042\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          3.000000\n",
       "max      27888.000000\n",
       "Name: Likes, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stadistics Retweets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    48429.000000\n",
       "mean         7.263664\n",
       "std         69.987750\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          2.000000\n",
       "max       6164.000000\n",
       "Name: Retweets, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# score\n",
    "# numero de likes i de retweets normalitzem\n",
    "\n",
    "# per saber quina normalització aplicar\n",
    "print('Stadistics Number of Hashtags')\n",
    "display(processed_tweets_df['Hashtags_count'].describe())\n",
    "\n",
    "print('\\nStadistics Likes')\n",
    "display(processed_tweets_df['Likes'].describe())\n",
    "\n",
    "print('\\nStadistics Retweets')\n",
    "display(processed_tweets_df['Retweets'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4bed7e04-f269-4777-a090-0fcd40beb476",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1731080989033,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "4bed7e04-f269-4777-a090-0fcd40beb476",
    "outputId": "a9c60494-0dcf-479f-f46b-df1b2afccf5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column 'Hashtags_count' contains outliers.\n",
      "The column 'Likes' contains outliers.\n",
      "The column 'Retweets' contains outliers.\n"
     ]
    }
   ],
   "source": [
    "# Display the rows containing outliers\n",
    "detect_outliers_iqr(processed_tweets_df, 'Hashtags_count')\n",
    "detect_outliers_iqr(processed_tweets_df, 'Likes')\n",
    "detect_outliers_iqr(processed_tweets_df, 'Retweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca6231e-5cb8-4d72-ad99-be86cccb150c",
   "metadata": {},
   "source": [
    "Apply logarithmic normalization to our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b7cfb164-535f-4ee3-a361-b05dc6e4c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstly generate new columns with the normlized data\n",
    "# apply logarithmic transformation (adding 1 to avoid log(0) issues)\n",
    "processed_tweets_df['Log Likes'] = np.log1p(processed_tweets_df['Likes'])\n",
    "processed_tweets_df['Log Retweets'] = np.log1p(processed_tweets_df['Retweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc502780-4686-4469-8340-c666f0394631",
   "metadata": {},
   "outputs": [],
   "source": [
    "likes = dict(zip(processed_tweets_df['docId'], processed_tweets_df['Log Likes']))\n",
    "retweets = dict(zip(processed_tweets_df['docId'], processed_tweets_df['Log Retweets']))\n",
    "hashtags = dict(zip(processed_tweets_df['docId'], processed_tweets_df['Hashtags_count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c2feb-f337-4416-8028-9c44ce77bb87",
   "metadata": {},
   "source": [
    "Function to build the score based on popularity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61fcac14-c628-41c0-b9d0-f153c603c0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_score(likes, retweets, hashtags, weigh_1, weigh_2, weight_3):\n",
    "    \n",
    "    popularity_score = likes * weigh_1 + retweets * weigh_2 + hashtags * weight_3\n",
    "\n",
    "    return popularity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "00bac61d-5a5d-4e98-8dc0-04035817707a",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731080989911,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "00bac61d-5a5d-4e98-8dc0-04035817707a"
   },
   "outputs": [],
   "source": [
    "def our_rank_documents(terms, docs, index, idf, tf, likes, retweets, hashtags, weights):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "\n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "\n",
    "    Returns:\n",
    "    Print the list of ranked documents\n",
    "    \"\"\"\n",
    "\n",
    "    # I'm interested only on the element of the docVector corresponding to the query terms\n",
    "    # The remaining elements would became 0 when multiplied to the query_vector\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) # I call doc_vectors[k] for a nonexistent key k, the key-value pair (k,[0]*len(terms)) will be automatically added to the dictionary\n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms)  # get the frequency of each term in the query.\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        ## Compute tf*idf(normalize TF as done with documents)\n",
    "        query_vector[termIndex]= query_terms_count[term]/ query_norm * idf[term]\n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc_index, (doc, postings) in enumerate(index[term]):\n",
    "\n",
    "            #tf[term][0] will contain the tf of the term \"term\" in the doc 26\n",
    "            if doc in docs:\n",
    "\n",
    "                # obtain the likes and retweets of the doc\n",
    "                number_likes = likes[doc]\n",
    "                number_retweets = retweets[doc]\n",
    "                number_hashtags = hashtags[doc]\n",
    "\n",
    "                # popularity \n",
    "                score_popularity = popularity_score(number_likes, number_retweets, number_hashtags, weights[0], weights[1], weights[2])\n",
    "                \n",
    "                doc_vectors[doc][termIndex] = tf[term][doc_index] * idf[term] + score_popularity\n",
    "\n",
    "    # Calculate the score of each doc\n",
    "    # compute the cosine similarity between queyVector and each docVector:\n",
    "    # HINT: you can use the dot product because in case of normalized vectors it corresponds to the cosine similarity\n",
    "    # see np.dot\n",
    "\n",
    "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "\n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "    result_scores = [x[0] for x in doc_scores]\n",
    "\n",
    "    if len(result_docs) == 0:\n",
    "        print('No results found, try again')\n",
    "        query = input()\n",
    "        docs = search_our_score(query, index)\n",
    "    return result_docs, result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e0114d4e-9b8d-436b-950f-f70f88b3d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_our_score(query, index):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms.\n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = process_tweet(query)\n",
    "    docs = set()\n",
    "\n",
    "    # parameters\n",
    "    # explain weights based on real aspects in twitter\n",
    "    weights = [0.3, 0.5, 0.2]\n",
    "\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"\n",
    "            term_docs=[posting[0] for posting in index[term]]\n",
    "            docs |= set(term_docs)\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs = our_rank_documents(query, docs, index, idf, tf, likes, retweets, hashtags, weights)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4bb7142f-d23f-4c25-a0df-fa7fbb83e0ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 15989 retrieved documents for the query 'Indian government response to farmers':\n",
      "\n",
      "docId = doc_2727\t score = 27.0626\n",
      "docId = doc_36986\t score = 24.2098\n",
      "docId = doc_16637\t score = 24.1463\n",
      "docId = doc_5169\t score = 23.1911\n",
      "docId = doc_22724\t score = 22.5843\n",
      "docId = doc_3500\t score = 22.0304\n",
      "docId = doc_1353\t score = 20.2666\n",
      "docId = doc_34869\t score = 19.9662\n",
      "docId = doc_5936\t score = 19.581\n",
      "docId = doc_19383\t score = 19.1091\n",
      "docId = doc_27956\t score = 18.8689\n",
      "docId = doc_36881\t score = 18.7084\n",
      "docId = doc_12753\t score = 18.5225\n",
      "docId = doc_27784\t score = 18.3251\n",
      "docId = doc_25955\t score = 17.9912\n",
      "docId = doc_32833\t score = 17.783\n",
      "docId = doc_19361\t score = 17.4371\n",
      "docId = doc_43834\t score = 17.3735\n",
      "docId = doc_4926\t score = 17.1857\n",
      "docId = doc_7778\t score = 17.111\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 15767 retrieved documents for the query 'International support for farmers':\n",
      "\n",
      "docId = doc_19243\t score = 29.1035\n",
      "docId = doc_44945\t score = 25.8663\n",
      "docId = doc_27791\t score = 23.2539\n",
      "docId = doc_3203\t score = 23.095\n",
      "docId = doc_19325\t score = 20.9605\n",
      "docId = doc_859\t score = 17.1277\n",
      "docId = doc_13630\t score = 16.8518\n",
      "docId = doc_33881\t score = 16.7243\n",
      "docId = doc_38783\t score = 16.6725\n",
      "docId = doc_8193\t score = 16.1062\n",
      "docId = doc_16055\t score = 16.0017\n",
      "docId = doc_31312\t score = 15.6512\n",
      "docId = doc_29408\t score = 15.6362\n",
      "docId = doc_29001\t score = 15.4938\n",
      "docId = doc_37003\t score = 15.4701\n",
      "docId = doc_27720\t score = 15.1665\n",
      "docId = doc_38012\t score = 15.1134\n",
      "docId = doc_46695\t score = 15.0147\n",
      "docId = doc_26650\t score = 14.5571\n",
      "docId = doc_20780\t score = 14.2696\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 14911 retrieved documents for the query 'Demands of farmers' protests':\n",
      "\n",
      "docId = doc_42516\t score = 28.1975\n",
      "docId = doc_36441\t score = 23.5794\n",
      "docId = doc_9979\t score = 22.6328\n",
      "docId = doc_45283\t score = 22.5266\n",
      "docId = doc_36996\t score = 21.5457\n",
      "docId = doc_43660\t score = 21.5094\n",
      "docId = doc_19633\t score = 19.9498\n",
      "docId = doc_14779\t score = 19.7732\n",
      "docId = doc_28694\t score = 19.699\n",
      "docId = doc_24430\t score = 19.5893\n",
      "docId = doc_2727\t score = 19.5184\n",
      "docId = doc_37068\t score = 19.4453\n",
      "docId = doc_47735\t score = 19.1157\n",
      "docId = doc_37143\t score = 18.6871\n",
      "docId = doc_31702\t score = 18.4557\n",
      "docId = doc_13630\t score = 18.1814\n",
      "docId = doc_14324\t score = 18.0988\n",
      "docId = doc_36332\t score = 17.1657\n",
      "docId = doc_14114\t score = 17.0384\n",
      "docId = doc_28839\t score = 16.822\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 15935 retrieved documents for the query 'Police action during farmers protest':\n",
      "\n",
      "docId = doc_30062\t score = 23.4226\n",
      "docId = doc_23286\t score = 23.0782\n",
      "docId = doc_16961\t score = 21.9283\n",
      "docId = doc_18802\t score = 21.768\n",
      "docId = doc_3174\t score = 21.221\n",
      "docId = doc_13980\t score = 19.869\n",
      "docId = doc_22796\t score = 18.3989\n",
      "docId = doc_14625\t score = 17.9629\n",
      "docId = doc_24962\t score = 17.8119\n",
      "docId = doc_20344\t score = 17.6438\n",
      "docId = doc_38073\t score = 16.581\n",
      "docId = doc_44054\t score = 16.3197\n",
      "docId = doc_19870\t score = 16.0621\n",
      "docId = doc_3227\t score = 16.0303\n",
      "docId = doc_36704\t score = 15.9723\n",
      "docId = doc_5807\t score = 15.9533\n",
      "docId = doc_47052\t score = 15.9362\n",
      "docId = doc_4926\t score = 15.8735\n",
      "docId = doc_32866\t score = 15.8136\n",
      "docId = doc_13630\t score = 15.7455\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top 20 results out of 4394 retrieved documents for the query 'Schedules and locations of demonstrations and protests':\n",
      "\n",
      "docId = doc_19010\t score = 32.288\n",
      "docId = doc_19312\t score = 27.8811\n",
      "docId = doc_47409\t score = 26.3069\n",
      "docId = doc_20732\t score = 26.2286\n",
      "docId = doc_43892\t score = 25.1184\n",
      "docId = doc_20809\t score = 24.6904\n",
      "docId = doc_40237\t score = 23.388\n",
      "docId = doc_38189\t score = 22.0464\n",
      "docId = doc_37942\t score = 21.5035\n",
      "docId = doc_38629\t score = 20.2077\n",
      "docId = doc_45564\t score = 20.1828\n",
      "docId = doc_46453\t score = 19.2674\n",
      "docId = doc_1592\t score = 19.0794\n",
      "docId = doc_39132\t score = 18.7309\n",
      "docId = doc_43347\t score = 18.6794\n",
      "docId = doc_20722\t score = 18.6743\n",
      "docId = doc_45516\t score = 18.4977\n",
      "docId = doc_46560\t score = 17.3455\n",
      "docId = doc_2319\t score = 17.1176\n",
      "docId = doc_19383\t score = 17.0816\n"
     ]
    }
   ],
   "source": [
    "top = 20\n",
    "results = {}  # dictionary to store results for each query\n",
    "\n",
    "# iterate through queries\n",
    "for i, query in enumerate(queries):\n",
    "    # execute the search function\n",
    "    ranked_docs, result_scores = search_our_score(query, index)\n",
    "\n",
    "    # store results in the dictionary\n",
    "    results[f'ranked_docs_q{i+1}'] = ranked_docs\n",
    "    results[f'result_scores_q{i+1}'] = result_scores\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------------------------------')\n",
    "    # print the top documents and their scores\n",
    "\n",
    "    print(f\"\\nTop {top} results out of {len(ranked_docs)} retrieved documents for the query '{query}':\\n\")\n",
    "    for doc_id, score in zip(ranked_docs[:top], result_scores[:top]):\n",
    "        print(f'docId = {doc_id}\\t score = {round(score, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ec0de-a251-4d40-b0c7-5a483f24ddf7",
   "metadata": {
    "id": "3b5ec0de-a251-4d40-b0c7-5a483f24ddf7"
   },
   "source": [
    "- **BM25**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "FPnZi9H_jxxi",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731080989912,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "FPnZi9H_jxxi"
   },
   "outputs": [],
   "source": [
    "def rank_documents_bm25 (terms, docs, index, idf, tf, k1, b, N, doc_length, lavg):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the BM25 weights\n",
    "\n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    k1 -- tunning parameter controling document term frequency scaling\n",
    "    b -- tunning parameter controling the scaling by document length\n",
    "    N -- number of documents\n",
    "    doc_lenght -- dictionary with lenghts of all documents\n",
    "    lavg -- average document length in the whole collection\n",
    "\n",
    "    Returns:\n",
    "    list of ranked documents\n",
    "    scores of the documents\n",
    "    \"\"\"\n",
    "\n",
    "    # I'm interested only on the element of the docVector corresponding to the query terms\n",
    "    # The remaining elements would became 0 when multiplied to the query_vector\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) # I call doc_vectors[k] for a nonexistent key k, the key-value pair (k,[0]*len(terms)) will be automatically added to the dictionary\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        dft = len(index[term]) #in how many documents does it appear\n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc_index, (doc, postings) in enumerate(index[term]):\n",
    "\n",
    "            if doc in docs:\n",
    "                ld = doc_length[doc] #document length\n",
    "                doc_vectors[doc][termIndex] = np.log(N/dft) * (((k1+1)*tf[term][doc_index]) / (k1*((1-b)+b*( ld / lavg ) ) + tf[term][doc_index]))\n",
    "\n",
    "    # Calculate the score of each doc\n",
    "    doc_scores=[[np.sum(curDocVec), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "    result_scores = [x[0] for x in doc_scores]\n",
    "    if len(result_docs) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "\n",
    "    return result_docs, result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "n9x9CkuQlEZS",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731080989912,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "n9x9CkuQlEZS"
   },
   "outputs": [],
   "source": [
    "def search_bm25(query, index, k1, b, N, doc_length, lavg):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain all of the query terms.\n",
    "    So, we will get the list of documents for each query term, and take the intersaction of them.\n",
    "    \"\"\"\n",
    "    query = process_tweet(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"\n",
    "            term_docs = [posting[0] for posting in index[term]]\n",
    "\n",
    "            # docs = docs Intersaction term_docs\n",
    "            if len(docs) == 0:\n",
    "              docs = set(term_docs)\n",
    "            else:\n",
    "              docs.intersaction(set(term_docs))\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs, result_scores = rank_documents_bm25 (query, docs, index, idf, tf, k1, b, N, doc_length, lavg)\n",
    "    return ranked_docs, result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "g0R0uRO_kosj",
   "metadata": {
    "executionInfo": {
     "elapsed": 2356,
     "status": "ok",
     "timestamp": 1731080992260,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "g0R0uRO_kosj"
   },
   "outputs": [],
   "source": [
    "# Ld\n",
    "doc_length = dict()\n",
    "for i, row in processed_tweets_df.iterrows():\n",
    "  doc_length[row['docId']]= len(row['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "SSZYPE73kr4O",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1731080992261,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "SSZYPE73kr4O"
   },
   "outputs": [],
   "source": [
    "# Lavg\n",
    "lavg = 0\n",
    "for length in doc_length.values():\n",
    "  lavg+=length\n",
    "\n",
    "lavg = round(lavg / len(doc_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2mv2Pil7kyOq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2775,
     "status": "ok",
     "timestamp": 1731080995029,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "2mv2Pil7kyOq",
    "outputId": "663d70f4-af0c-4320-eb7c-46a6cdb0d962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Top 20 results out of 2719 for the searched query Indian government response to farmers:\n",
      "\n",
      "docId = doc_13543\t score = 6.018461467422177\n",
      "docId = doc_30422\t score = 5.711082995326188\n",
      "docId = doc_41848\t score = 5.47864863495953\n",
      "docId = doc_40125\t score = 5.47864863495953\n",
      "docId = doc_40124\t score = 5.47864863495953\n",
      "docId = doc_38240\t score = 5.47864863495953\n",
      "docId = doc_31710\t score = 5.47864863495953\n",
      "docId = doc_3116\t score = 5.47864863495953\n",
      "docId = doc_29545\t score = 5.47864863495953\n",
      "docId = doc_26363\t score = 5.47864863495953\n",
      "docId = doc_17769\t score = 5.47864863495953\n",
      "docId = doc_14237\t score = 5.47864863495953\n",
      "docId = doc_12228\t score = 5.47864863495953\n",
      "docId = doc_11484\t score = 5.47864863495953\n",
      "docId = doc_31188\t score = 5.451518096785867\n",
      "docId = doc_27778\t score = 5.451518096785867\n",
      "docId = doc_34728\t score = 5.424654938061487\n",
      "docId = doc_36211\t score = 4.8267924274395\n",
      "docId = doc_46211\t score = 4.7309752080362335\n",
      "docId = doc_42096\t score = 4.7309752080362335\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Top 20 results out of 443 for the searched query International support for farmers:\n",
      "\n",
      "docId = doc_859\t score = 7.671749011909789\n",
      "docId = doc_21846\t score = 7.671749011909789\n",
      "docId = doc_38762\t score = 5.292825659478492\n",
      "docId = doc_21630\t score = 5.267141544898828\n",
      "docId = doc_27400\t score = 5.241705497454418\n",
      "docId = doc_44066\t score = 4.907132967516674\n",
      "docId = doc_12950\t score = 4.826802064713101\n",
      "docId = doc_31474\t score = 4.45532336932703\n",
      "docId = doc_28358\t score = 4.433039688553589\n",
      "docId = doc_25064\t score = 4.38913442632224\n",
      "docId = doc_27294\t score = 4.36750631968045\n",
      "docId = doc_40138\t score = 4.356849957244348\n",
      "docId = doc_6713\t score = 3.963816363142042\n",
      "docId = doc_32164\t score = 3.9279957077723493\n",
      "docId = doc_29112\t score = 3.8919924107560764\n",
      "docId = doc_48125\t score = 3.86657675462777\n",
      "docId = doc_6031\t score = 3.8471954175118412\n",
      "docId = doc_41492\t score = 3.809009855055148\n",
      "docId = doc_6920\t score = 3.790199929844999\n",
      "docId = doc_44813\t score = 3.790199929844999\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Top 20 results out of 496 for the searched query Demands of farmers' protests:\n",
      "\n",
      "docId = doc_15908\t score = 6.570517361197074\n",
      "docId = doc_17929\t score = 5.510834223927822\n",
      "docId = doc_43415\t score = 5.140344916805858\n",
      "docId = doc_887\t score = 4.806303976565441\n",
      "docId = doc_43810\t score = 4.75883430766109\n",
      "docId = doc_43799\t score = 4.75883430766109\n",
      "docId = doc_43790\t score = 4.75883430766109\n",
      "docId = doc_18273\t score = 4.735449372488309\n",
      "docId = doc_17894\t score = 4.735449372488309\n",
      "docId = doc_30921\t score = 4.458639259559197\n",
      "docId = doc_15930\t score = 4.348069752639702\n",
      "docId = doc_41953\t score = 4.326322510000587\n",
      "docId = doc_1940\t score = 4.326322510000587\n",
      "docId = doc_10445\t score = 4.326322510000587\n",
      "docId = doc_12705\t score = 4.298524399105498\n",
      "docId = doc_39659\t score = 4.283474185229341\n",
      "docId = doc_10879\t score = 4.251162221997042\n",
      "docId = doc_46147\t score = 4.2096357732472125\n",
      "docId = doc_10418\t score = 4.2096357732472125\n",
      "docId = doc_47735\t score = 4.019610058713129\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Top 20 results out of 1448 for the searched query Police action during farmers protest:\n",
      "\n",
      "docId = doc_32026\t score = 7.876383763879883\n",
      "docId = doc_7588\t score = 4.590492068489268\n",
      "docId = doc_14464\t score = 4.5857817738996225\n",
      "docId = doc_45728\t score = 4.531555522404657\n",
      "docId = doc_9604\t score = 4.442747882312812\n",
      "docId = doc_25479\t score = 4.253499225936463\n",
      "docId = doc_32162\t score = 4.217107789753413\n",
      "docId = doc_14699\t score = 4.046400831226678\n",
      "docId = doc_36833\t score = 3.9768369790340747\n",
      "docId = doc_18802\t score = 3.9354429173039334\n",
      "docId = doc_47283\t score = 3.93264915034554\n",
      "docId = doc_14625\t score = 3.85044955227455\n",
      "docId = doc_11674\t score = 3.717808658289146\n",
      "docId = doc_22518\t score = 3.5268791993420328\n",
      "docId = doc_33473\t score = 3.427697617212414\n",
      "docId = doc_34650\t score = 3.395930871033868\n",
      "docId = doc_32988\t score = 3.365075086055999\n",
      "docId = doc_37797\t score = 3.348074313656878\n",
      "docId = doc_31516\t score = 3.348074313656878\n",
      "docId = doc_25399\t score = 3.348074313656878\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Top 20 results out of 16 for the searched query Schedules and locations of demonstrations and protests:\n",
      "\n",
      "docId = doc_43892\t score = 8.99339161121647\n",
      "docId = doc_46453\t score = 6.196198047800415\n",
      "docId = doc_45516\t score = 5.970368506194933\n",
      "docId = doc_26556\t score = 3.5142609624381103\n",
      "docId = doc_3228\t score = 3.188162113127597\n",
      "docId = doc_20809\t score = 2.5712504122679753\n",
      "docId = doc_20722\t score = 2.5712504122679753\n",
      "docId = doc_48234\t score = 2.1801013437532037\n",
      "docId = doc_23067\t score = 2.0809524371121184\n",
      "docId = doc_47409\t score = 2.0275201857865777\n",
      "docId = doc_47369\t score = 2.0275201857865777\n",
      "docId = doc_46560\t score = 2.0275201857865777\n",
      "docId = doc_9358\t score = 1.8702769902614576\n",
      "docId = doc_45381\t score = 1.6076152887049262\n",
      "docId = doc_48029\t score = 1.5361067711391412\n",
      "docId = doc_32308\t score = 1.4526786813907067\n"
     ]
    }
   ],
   "source": [
    "ranked_docs = [0]*5\n",
    "result_scores = [0]*5\n",
    "k1 = 2\n",
    "b = 0.5\n",
    "N = len(relevance_features_df)\n",
    "\n",
    "i = 0\n",
    "for query in queries:\n",
    "\n",
    "  ranked_docs[i], result_scores[i] = search_bm25(query, index, k1, b, N, doc_length, lavg)\n",
    "  top = 20\n",
    "  print(\"\\n----------------------------------------------------------------------------------------------------------\")\n",
    "  print(\"Top {} results out of {} for the searched query {}:\\n\".format(top, len(ranked_docs[i]), query))\n",
    "\n",
    "  j=0\n",
    "  for j in range(len(ranked_docs[i])):\n",
    "    if (j < top):\n",
    "      print(\"docId = {}\\t score = {}\".format(ranked_docs[i][j], result_scores[i][j]))\n",
    "  i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf2af8-f8ae-4cee-a76b-fe52bb9368db",
   "metadata": {
    "id": "bdbf2af8-f8ae-4cee-a76b-fe52bb9368db"
   },
   "source": [
    "**2. Return a top-20 list of documents for each of the 5 queries, using word2vec + cosine similarity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "yw1DSgLTqOIU",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1731080995854,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "yw1DSgLTqOIU"
   },
   "outputs": [],
   "source": [
    "lines = processed_tweets_df['Tweet']\n",
    "clean_tweets = []\n",
    "for line in lines:\n",
    "\n",
    "  clean_tweets.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "525Sydwwqk3K",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731080995854,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "525Sydwwqk3K"
   },
   "outputs": [],
   "source": [
    "sentences = clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "kRaYn2Ncn4a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731080995855,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "kRaYn2Ncn4a6"
   },
   "outputs": [],
   "source": [
    "def search_word2vec(query, index, vector_size):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain all of the query terms.\n",
    "    So, we will get the list of documents for each query term, and take the intersaction of them.\n",
    "    \"\"\"\n",
    "    query = process_tweet(query)\n",
    "    docs = set()\n",
    "    for term in query:\n",
    "        try:\n",
    "            # store in term_docs the ids of the docs that contain \"term\"\n",
    "            term_docs = [posting[0] for posting in index[term]]\n",
    "\n",
    "            # docs = docs Intersaction term_docs\n",
    "            if len(docs) == 0:\n",
    "              docs = set(term_docs)\n",
    "            else:\n",
    "              docs.intersaction(set(term_docs))\n",
    "        except:\n",
    "            #term is not in index\n",
    "            pass\n",
    "    docs = list(docs)\n",
    "    ranked_docs, result_scores = rank_documents_word2vec(query, docs, vector_size)\n",
    "    return ranked_docs, result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "kJpqpifyoFcx",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731080995855,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "kJpqpifyoFcx"
   },
   "outputs": [],
   "source": [
    "def rank_documents_word2vec (terms, docs, v_size):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on word2vec\n",
    "\n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "\n",
    "    Returns:\n",
    "    list of ranked documents\n",
    "    scores of the documents\n",
    "    \"\"\"\n",
    "    tweet2vec = {'docId': docs}\n",
    "\n",
    "    # Computing a vector for each word\n",
    "    sentence = []\n",
    "    for i, row in processed_tweets_df.iterrows(): # for each tweet\n",
    "      sentences.append(row['Tweet'])\n",
    "    model = Word2Vec(sentences, vector_size=100)\n",
    "\n",
    "    for i, row in processed_tweets_df.iterrows():\n",
    "      if row['docId'] in docs:\n",
    "        doc_vector = [model.wv[word] for word in row['Tweet']]\n",
    "        tweet2vec[row['docId']]=np.mean(doc_vector, axis=0)\n",
    "\n",
    "    # Computing the vector for the query\n",
    "    query2vec = [model.wv[word] for word in query if word in model.wv.key_to_index]\n",
    "    query2vec = np.mean(query2vec, axis=0)\n",
    "\n",
    "    # Calculate the score of each doc\n",
    "    doc_scores=[[np.dot(curDocVec, query2vec), doc] for doc, curDocVec in tweet2vec.items() if doc in docs]\n",
    "    doc_scores.sort(reverse=True)\n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "    result_scores = [x[0] for x in doc_scores]\n",
    "    if len(result_docs) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "\n",
    "    return result_docs, result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "LJzYs4LOnviI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261422,
     "status": "ok",
     "timestamp": 1731081257269,
     "user": {
      "displayName": "ENEKO TREVIÑO BERECIARTUA",
      "userId": "16440135757561316378"
     },
     "user_tz": -60
    },
    "id": "LJzYs4LOnviI",
    "outputId": "df3bbc9d-3612-42dc-cc8b-f0c1b258cccb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Top 20 results out of 2719 for the searched query Indian government response to farmers:\n",
      "\n",
      "docId = doc_8866\t score = 10.882384300231934\n",
      "docId = doc_28972\t score = 10.8820161819458\n",
      "docId = doc_36886\t score = 10.856545448303223\n",
      "docId = doc_1672\t score = 10.845367431640625\n",
      "docId = doc_1670\t score = 10.833749771118164\n",
      "docId = doc_32181\t score = 10.828836441040039\n",
      "docId = doc_42913\t score = 10.827942848205566\n",
      "docId = doc_22895\t score = 10.82154655456543\n",
      "docId = doc_27384\t score = 10.80708122253418\n",
      "docId = doc_45348\t score = 10.806890487670898\n",
      "docId = doc_26898\t score = 10.803295135498047\n",
      "docId = doc_43814\t score = 10.803068161010742\n",
      "docId = doc_5511\t score = 10.80180835723877\n",
      "docId = doc_1265\t score = 10.796810150146484\n",
      "docId = doc_1242\t score = 10.796810150146484\n",
      "docId = doc_1128\t score = 10.796810150146484\n",
      "docId = doc_8073\t score = 10.777034759521484\n",
      "docId = doc_11845\t score = 10.776662826538086\n",
      "docId = doc_38085\t score = 10.762916564941406\n",
      "docId = doc_35055\t score = 10.752077102661133\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Top 20 results out of 443 for the searched query International support for farmers:\n",
      "\n",
      "docId = doc_9046\t score = 12.860756874084473\n",
      "docId = doc_32923\t score = 12.731843948364258\n",
      "docId = doc_37775\t score = 12.708637237548828\n",
      "docId = doc_33881\t score = 12.696150779724121\n",
      "docId = doc_6713\t score = 12.679515838623047\n",
      "docId = doc_44140\t score = 12.63978099822998\n",
      "docId = doc_6883\t score = 12.626504898071289\n",
      "docId = doc_43188\t score = 12.622400283813477\n",
      "docId = doc_40758\t score = 12.608071327209473\n",
      "docId = doc_36205\t score = 12.604903221130371\n",
      "docId = doc_40846\t score = 12.6029634475708\n",
      "docId = doc_3447\t score = 12.593859672546387\n",
      "docId = doc_45070\t score = 12.58863639831543\n",
      "docId = doc_31474\t score = 12.580080032348633\n",
      "docId = doc_42972\t score = 12.55678653717041\n",
      "docId = doc_4107\t score = 12.53271484375\n",
      "docId = doc_3517\t score = 12.526780128479004\n",
      "docId = doc_31472\t score = 12.514620780944824\n",
      "docId = doc_40138\t score = 12.504348754882812\n",
      "docId = doc_6920\t score = 12.502291679382324\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Top 20 results out of 496 for the searched query Demands of farmers' protests:\n",
      "\n",
      "docId = doc_10292\t score = 13.893990516662598\n",
      "docId = doc_36885\t score = 13.863250732421875\n",
      "docId = doc_36890\t score = 13.807999610900879\n",
      "docId = doc_36628\t score = 13.807999610900879\n",
      "docId = doc_38712\t score = 13.761845588684082\n",
      "docId = doc_40148\t score = 13.728888511657715\n",
      "docId = doc_10875\t score = 13.72413444519043\n",
      "docId = doc_10879\t score = 13.697843551635742\n",
      "docId = doc_36735\t score = 13.679884910583496\n",
      "docId = doc_36607\t score = 13.665979385375977\n",
      "docId = doc_10621\t score = 13.625481605529785\n",
      "docId = doc_10296\t score = 13.613475799560547\n",
      "docId = doc_17340\t score = 13.601438522338867\n",
      "docId = doc_10573\t score = 13.599063873291016\n",
      "docId = doc_10002\t score = 13.599063873291016\n",
      "docId = doc_25486\t score = 13.577644348144531\n",
      "docId = doc_10418\t score = 13.57286548614502\n",
      "docId = doc_18128\t score = 13.568063735961914\n",
      "docId = doc_9028\t score = 13.558449745178223\n",
      "docId = doc_48036\t score = 13.558449745178223\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Top 20 results out of 1448 for the searched query Police action during farmers protest:\n",
      "\n",
      "docId = doc_1719\t score = 15.442459106445312\n",
      "docId = doc_33389\t score = 15.060827255249023\n",
      "docId = doc_13141\t score = 15.059541702270508\n",
      "docId = doc_14177\t score = 15.055861473083496\n",
      "docId = doc_25399\t score = 15.030957221984863\n",
      "docId = doc_33565\t score = 15.029595375061035\n",
      "docId = doc_15870\t score = 15.023026466369629\n",
      "docId = doc_45728\t score = 15.022327423095703\n",
      "docId = doc_14588\t score = 15.000823020935059\n",
      "docId = doc_14185\t score = 14.970049858093262\n",
      "docId = doc_23968\t score = 14.937399864196777\n",
      "docId = doc_21520\t score = 14.930732727050781\n",
      "docId = doc_18783\t score = 14.928152084350586\n",
      "docId = doc_14525\t score = 14.926989555358887\n",
      "docId = doc_13416\t score = 14.925275802612305\n",
      "docId = doc_3360\t score = 14.91730785369873\n",
      "docId = doc_24778\t score = 14.906076431274414\n",
      "docId = doc_23360\t score = 14.902112007141113\n",
      "docId = doc_33014\t score = 14.898853302001953\n",
      "docId = doc_14502\t score = 14.882033348083496\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Top 20 results out of 16 for the searched query Schedules and locations of demonstrations and protests:\n",
      "\n",
      "docId = doc_32308\t score = 14.729284286499023\n",
      "docId = doc_43892\t score = 14.654309272766113\n",
      "docId = doc_3228\t score = 14.458234786987305\n",
      "docId = doc_48029\t score = 14.409436225891113\n",
      "docId = doc_23067\t score = 14.265942573547363\n",
      "docId = doc_9358\t score = 14.188628196716309\n",
      "docId = doc_47409\t score = 14.102112770080566\n",
      "docId = doc_47369\t score = 14.102112770080566\n",
      "docId = doc_46560\t score = 14.102112770080566\n",
      "docId = doc_20809\t score = 13.908699035644531\n",
      "docId = doc_20722\t score = 13.908699035644531\n",
      "docId = doc_48234\t score = 13.814553260803223\n",
      "docId = doc_26556\t score = 13.646644592285156\n",
      "docId = doc_46453\t score = 13.344428062438965\n",
      "docId = doc_45381\t score = 13.23910140991211\n",
      "docId = doc_45516\t score = 12.940328598022461\n"
     ]
    }
   ],
   "source": [
    "ranked_docs = [0]*5\n",
    "result_scores = [0]*5\n",
    "k1 = 2\n",
    "b = 0.5\n",
    "N = len(relevance_features_df)\n",
    "\n",
    "i = 0\n",
    "for query in queries:\n",
    "\n",
    "  ranked_docs[i], result_scores[i] = search_word2vec(query, index, 100)\n",
    "  top = 20\n",
    "  print(\"\\n----------------------------------------------------------------------------------------------------------\")\n",
    "  print(\"Top {} results out of {} for the searched query {}:\\n\".format(top, len(ranked_docs[i]), query))\n",
    "    \n",
    "  j=0\n",
    "  for j in range(len(ranked_docs[i])):\n",
    "    if (j < top):\n",
    "      print(\"docId = {}\\t score = {}\".format(ranked_docs[i][j], result_scores[i][j]))\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e4316-adf7-49f7-a123-18c453f3565d",
   "metadata": {
    "id": "576e4316-adf7-49f7-a123-18c453f3565d"
   },
   "source": [
    "**3. Can you imagine a better representation than word2vec? Justify your answer. (HINT - what about Doc2vec? Sentence2vec? Which are the pros and cons.**\n",
    "\n",
    "This part is developed in our report. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
